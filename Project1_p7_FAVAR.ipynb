{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0e4b4336",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import difflib\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import string\n",
    "import sys\n",
    "from datetime import timedelta\n",
    "from random import sample\n",
    "\n",
    "import folium\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyreadstat\n",
    "import seaborn as sns\n",
    "import statsmodels.tools.tools as sm\n",
    "import statsmodels.base as sb\n",
    "from folium.features import CustomIcon\n",
    "from folium.plugins import FastMarkerCluster, HeatMap, MarkerCluster\n",
    "from linearmodels.panel.model import PooledOLS\n",
    "from scipy.signal import savgol_filter\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "from statsmodels.tools.eval_measures import aic, rmse\n",
    "from statsmodels.tsa.api import VAR\n",
    "from statsmodels.tsa.vector_ar.svar_model import SVAR\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import yfinance as yf\n",
    "from yahoofinancials import YahooFinancials\n",
    "import pickle\n",
    "import array_to_latex as a2l\n",
    "import markdown\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pdfkit as pdf\n",
    "\n",
    "\n",
    "import random\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta\n",
    "from scipy.signal import savgol_filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d11bb6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Functions in /Users/leiflyu/miniforge3/lib/python3.9/site-packages (0.7.0)\r\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e798a5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install -U tslearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "03cbcdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\n",
    "    \"./markettrends0.csv\",\n",
    "    dtype={\n",
    "        \"state\": \"str\",\n",
    "        \"sa3_name16\": \"str\",\n",
    "        \"sa4_name16\": \"str\",\n",
    "        \"postcode\": \"str\",\n",
    "        \"state\": \"str\",\n",
    "        \"property_type\": \"str\",\n",
    "    },\n",
    ")\n",
    "ndata = data.fillna(\n",
    "    {\"Volume of new rental listings (1 month)\": 0, \"Volume of sales (1 month)\": 0}\n",
    ").dropna(subset=[\"postcode\"])\n",
    "ndatahouses = ndata[:][ndata.property_type == \"Houses\"]\n",
    "ndataunits = ndata[:][ndata.property_type == \"Units\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "113f95f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "UniqueNames_sa4 = ndatahouses.sa4_name16.unique()[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cba97a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('DataFrameDict_postcode.pickle', 'wb') as f:\n",
    "#     pickle.dump(DataFrameDict_postcode, f)\n",
    "with open('DataFrameDict_postcode.pickle', 'rb') as f:\n",
    "     DataFrameDict_postcode =  pickle.load(f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2551813b",
   "metadata": {},
   "outputs": [],
   "source": [
    "aveHPI_lv3 = []\n",
    "lst = [\"postcode\", \"sa4\", \"state\", \"logHPI\", \"logHPIdiff\"]\n",
    "# Calling DataFrame constructor on list\n",
    "for key in DataFrameDict_postcode.keys():\n",
    "    df = pd.DataFrame([], columns=lst)\n",
    "    df[\"Description\"] = DataFrameDict_postcode[key][\"value_at_date\"].loc[\n",
    "        (\"2020-01\" > DataFrameDict_postcode[key][\"value_at_date\"])\n",
    "        & (DataFrameDict_postcode[key][\"value_at_date\"] > \"1999-12\")\n",
    "    ]\n",
    "    df[\"logHPI\"] =np.log2(\n",
    "        DataFrameDict_postcode[key][\"Hedonic Home Value Index\"].loc[\n",
    "            (\"2020-01\" > DataFrameDict_postcode[key][\"value_at_date\"])\n",
    "            & (DataFrameDict_postcode[key][\"value_at_date\"] > \"1999-12\")\n",
    "        ]\n",
    "    )\n",
    "    df[\"postcode\"] = key\n",
    "    df[\"sa4\"] = DataFrameDict_postcode[key][\"sa4_name16\"].loc[\n",
    "        ( DataFrameDict_postcode[key][\"postcode\"] == key)]\n",
    "    df[\"state\"] = DataFrameDict_postcode[key][\"state\"].loc[\n",
    "        ( DataFrameDict_postcode[key][\"postcode\"] == key)]\n",
    "    \n",
    "    df[\"logHPIdiff\"] = df[\"logHPI\"].diff(1)\n",
    "    aveHPI_lv3.append(df)\n",
    "\n",
    "aveHPIdf_lv3 = pd.concat(aveHPI_lv3)\n",
    "aveHPIdf_lv3 = aveHPIdf_lv3.reset_index(drop=True)\n",
    "aveHPIdf_lv3['date'] = pd.to_datetime(aveHPIdf_lv3['Description'],errors = 'coerce')\n",
    "aveHPIdf_lv3['year'] = pd.DatetimeIndex(aveHPIdf_lv3['date']).year\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "97ef99a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def person_cat(postcode, lst):\n",
    "    df_tmp = pd.DataFrame([], columns=lst)\n",
    "    for key in DataFrameDict_HILDA.keys():\n",
    "        lst0 = list(set(lst) - set(DataFrameDict_HILDAp[key].columns))\n",
    "        lst1 = list(set(lst) - set(lst0))\n",
    "        df = (\n",
    "            DataFrameDict_HILDAp[key][lst1]\n",
    "            .loc[DataFrameDict_HILDAp[key][\"hhpcode\"] == postcode]\n",
    "            .astype(str)\n",
    "        )\n",
    "        df[\"date\"] = str(key)\n",
    "        df_tmp = pd.concat([df_tmp, df], axis=0, ignore_index=True)\n",
    "    df_dummy = pd.get_dummies(df_tmp, columns=df_tmp.columns[:-1], dummy_na=True)\n",
    "    dfHILDA = df_dummy.groupby(\"date\").mean().reset_index()\n",
    "    return nan_dum(dfHILDA)\n",
    "def house_cat(postcode, lst):\n",
    "    df_tmp = pd.DataFrame([], columns=lst)\n",
    "    for key in DataFrameDict_HILDA.keys():\n",
    "        lst0 = list(set(lst) - set(DataFrameDict_HILDA[key].columns))\n",
    "        lst1 = list(set(lst) - set(lst0))\n",
    "        df = (\n",
    "            DataFrameDict_HILDA[key][lst1]\n",
    "            .loc[DataFrameDict_HILDA[key][\"hhpcode\"] == postcode]\n",
    "            .astype(str)\n",
    "        )\n",
    "        df[\"date\"] = str(key)\n",
    "        df_tmp = pd.concat([df_tmp, df], axis=0, ignore_index=True)\n",
    "    df_dummy = pd.get_dummies(df_tmp, columns=df_tmp.columns[:-1], dummy_na=True)\n",
    "    dfHILDA = df_dummy.groupby(\"date\").mean().reset_index()\n",
    "    return nan_dum(dfHILDA)\n",
    "def person_num(postcode, lst):\n",
    "    df_tmp = pd.DataFrame([], columns=lst)\n",
    "    for key in DataFrameDict_HILDA.keys():\n",
    "        lst0 = list(set(lst) - set(DataFrameDict_HILDAp[key].columns))\n",
    "        lst1 = list(set(lst) - set(lst0))\n",
    "        df = DataFrameDict_HILDAp[key][lst1].loc[\n",
    "            DataFrameDict_HILDAp[key][\"hhpcode\"] == postcode\n",
    "        ]\n",
    "        df[\"date\"] = str(key)\n",
    "        df_tmp = pd.concat([df_tmp, df], axis=0, ignore_index=True)\n",
    "    dfHILDA = df_tmp.groupby(\"date\").agg({lambda x: x.mean(skipna=False)})\n",
    "    dfHILDA.columns = lst\n",
    "    return dfHILDA.reset_index()\n",
    "def house_num(postcode, lst):\n",
    "    df_tmp = pd.DataFrame([], columns=lst)\n",
    "    for key in DataFrameDict_HILDA.keys():\n",
    "        lst0 = list(set(lst) - set(DataFrameDict_HILDA[key].columns))\n",
    "        lst1 = list(set(lst) - set(lst0))\n",
    "        df = DataFrameDict_HILDA[key][lst1].loc[\n",
    "            DataFrameDict_HILDA[key][\"hhpcode\"] == postcode\n",
    "        ]\n",
    "        df[\"date\"] = str(key)\n",
    "        df_tmp = pd.concat([df_tmp, df], axis=0, ignore_index=True)\n",
    "    dfHILDA = df_tmp.groupby(\"date\").agg({lambda x: x.mean(skipna=False)})\n",
    "    dfHILDA.columns = lst\n",
    "    return dfHILDA.reset_index()\n",
    "def HILDAext_cat(postcode, lst1, lst2):\n",
    "    dfHILDA1 = house_cat(postcode, lst1)\n",
    "    dfHILDA1[\"date\"] = pd.to_datetime(dfHILDA1[\"date\"]) + pd.offsets.YearEnd()\n",
    "    dfHILDA2 = person_cat(postcode, lst2)\n",
    "    dfHILDA2[\"date\"] = pd.to_datetime(dfHILDA2[\"date\"]) + pd.offsets.YearEnd()\n",
    "    dfHILDA = pd.merge(dfHILDA1, dfHILDA2, on=\"date\", how=\"left\")\n",
    "    return dfHILDA\n",
    "def HILDAext_num(postcode, lst1, lst2):\n",
    "    dfHILDA1 = house_num(postcode, lst1)\n",
    "    dfHILDA1[\"date\"] = pd.to_datetime(dfHILDA1[\"date\"]) + pd.offsets.YearEnd()\n",
    "    dfHILDA2 = person_num(postcode, lst2)\n",
    "    dfHILDA2[\"date\"] = pd.to_datetime(dfHILDA2[\"date\"]) + pd.offsets.YearEnd()\n",
    "    dfHILDA = pd.merge(dfHILDA1, dfHILDA2, on=\"date\", how=\"left\")\n",
    "    return dfHILDA\n",
    "def q1(x):\n",
    "    return x.quantile(0.25)\n",
    "def q3(x):\n",
    "    return x.quantile(0.75)\n",
    "lst_age = [f'hgdob{i}' for i in range(1, 21)]\n",
    "\n",
    "def HILDAext_age(postcode):    \n",
    "    df_tmp = pd.DataFrame()\n",
    "    for key in DataFrameDict_HILDA.keys():\n",
    "        df = DataFrameDict_HILDA[key][lst_age].loc[DataFrameDict_HILDA[key][\"hhpcode\"] == postcode]\n",
    "        df[\"date\"] = str(key)\n",
    "        df = df.melt(id_vars='date', var_name='Indicator name', value_name='birth_date').sort_values('date', ascending=False).reset_index(drop=True)\n",
    "        df['birthDate'] = pd.to_datetime(df['birth_date'].replace(r'-','na',regex=True),errors = 'coerce')\n",
    "        df['year'] = pd.DatetimeIndex(df['birthDate']).year\n",
    "        df['age'] = key +1 - df['year']\n",
    "        df_tmp = pd.concat([df_tmp, df[['date','age']]], axis=0, ignore_index=True)\n",
    "    f = {'age': ['median', 'std', q1, q3,'count']} \n",
    "    dfHILDAage = df_tmp.groupby('date').agg(f)\n",
    "    dfHILDAage = dfHILDAage.set_axis(dfHILDAage.columns.map(''.join), axis=1, inplace=False).reset_index()\n",
    "    dfHILDAage[\"date\"] = pd.to_datetime(dfHILDAage[\"date\"]) + pd.offsets.YearEnd()\n",
    "    return dfHILDAage\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c765123f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def nan_dum(df):\n",
    "    df1_ohe = df\n",
    "    nan_df = df1_ohe.loc[:, df1_ohe.columns.str.endswith(\"_nan\")]\n",
    "    pattern = \"^([^_]*)_\"\n",
    "    regex = re.compile(pattern)\n",
    "    for index in df1_ohe.index:\n",
    "        for col_nan in nan_df.columns:\n",
    "            if df1_ohe.loc[index, col_nan] == 1:\n",
    "                col_id = regex.search(col_nan).group(1)\n",
    "                targets = df1_ohe.columns[df1_ohe.columns.str.startswith(col_id + \"_\")]\n",
    "                df1_ohe.loc[index, targets] = np.nan\n",
    "    df1_ohe.drop(\n",
    "        df1_ohe.columns[df1_ohe.columns.str.endswith(\"_nan\")], axis=1, inplace=True\n",
    "    )\n",
    "    return df1_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0b39da73",
   "metadata": {},
   "outputs": [],
   "source": [
    "varnames_catp = [\"ancob\", \"edhigh1\", \"anatsi\", \"chkb12\", \"sex\"]\n",
    "# varnames_nump = [\"wsce\", \"baynoa\"]\n",
    "varnames_nump = [\"wsce\"]\n",
    "varnames_cath = []\n",
    "#varnames_cath = [\"xpgroci\"]\n",
    "varnames_numh = [\"hsdebt\"]\n",
    "\n",
    "# UniqueNames_Hsa4 = avg_3.sa4.unique()[:-1]\n",
    "# DataFrameDict_Hsa4 = {elem: pd.DataFrame for elem in UniqueNames_Hsa4}\n",
    "\n",
    "# for key in DataFrameDict_Hsa4.keys():\n",
    "#     lstpcCL= ndatahouses['postcode'].loc[ndatahouses['sa4_name16'] == key].unique()\n",
    "#     lst0 = list(set(lstpcCL) - set(HILDAallpc))\n",
    "#     lstpc  = list(set(lstpcCL) - set(lst0))\n",
    "#     df_tmp = pd.DataFrame([])\n",
    "#     for key_pc in lstpc:\n",
    "#         HILDAextract_num = HILDAext_num(key_pc, varnames_numh, varnames_nump)\n",
    "#         HILDAextract_cat = HILDAext_cat(key_pc, varnames_cath, varnames_catp)\n",
    "#         HILDAextract_age = HILDAext_age(key_pc)\n",
    "#         HILDAextract = pd.merge(HILDAextract_num, HILDAextract_cat, on=\"date\", how=\"left\")\n",
    "#         HILDAextract = pd.merge( HILDAextract , HILDAextract_age, on=\"date\", how=\"left\")\n",
    "#         df_tmp = pd.concat([df_tmp, HILDAextract], axis=0, ignore_index=True)\n",
    "#     dfHILDA = df_tmp.groupby(\"date\").agg({lambda x: x.mean(skipna=True)})\n",
    "#     list1, list2 = zip(*dfHILDA.columns)\n",
    "#     dfHILDA.columns = list1\n",
    "#     DataFrameDict_Hsa4[key] = dfHILDA.reset_index()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "736eadd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('DataFrameDict_Hsa4.pickle', 'rb') as f:\n",
    "    DataFrameDict_Hsa4 =  pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "05e9bcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HILDA2PCsa4(key, marks):\n",
    "    df = DataFrameDict_Hsa4[key].interpolate(\"bfill\").interpolate(\"ffill\")\n",
    "    df = df.set_index(\"date\")\n",
    "    df1 = df.resample(\"Y\").mean().iloc[:, :]\n",
    "    \n",
    "    vrst = pd.DataFrame([])\n",
    "    for vn in df1.columns.values[1:]:\n",
    "        vrst = pd.concat([vrst, selectStationaySeries3(df1[vn], vn, marks)], axis=1)\n",
    "    vrdata = vrst.reset_index()\n",
    "    \n",
    "    pca = PCA()\n",
    "    X_train = vrdata.loc[:, vrdata.columns != \"date\"]\n",
    "    scaler = StandardScaler()\n",
    "    X_train_std = scaler.fit_transform(X_train)\n",
    "\n",
    "    pca.fit(X_train_std)\n",
    "    cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "    d = np.argmax(cumsum >= 0.9) + 1\n",
    "    print(d)\n",
    "\n",
    "    pca_d = PCA(n_components=d)\n",
    "    pca_d.fit(X_train_std)\n",
    "    X_pca_d = pca_d.transform(X_train_std)\n",
    "    PCnames = []\n",
    "    for i in range(1, d + 1, 1):\n",
    "        PCnames.append(f\"sa4PC{i}\")\n",
    "    pcadf = pd.DataFrame(X_pca_d, columns=PCnames)\n",
    "    pcadf['date'] = DataFrameDict_Hsa4[key]['date']  \n",
    "    pcadf[\"date\"] = pd.to_datetime(pcadf[\"date\"]) - pd.offsets.MonthEnd(6)\n",
    "    pcadf[\"date\"] = pcadf[\"date\"]\n",
    "    return pcadf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f1f9e0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HILDAvarExt(key, marks):\n",
    "    df = DataFrameDict_Hsa4[key].interpolate(\"bfill\").interpolate(\"ffill\")\n",
    "    df = df.set_index(\"date\")\n",
    "    df1 = df.resample(\"Y\").mean().iloc[:, :]\n",
    "    vrst = pd.DataFrame([], columns = df_marks['Variable Names'].values)\n",
    "    lst = list( set(df_marks['Variable Names'].values) & set(df1.columns.values[1:]))\n",
    "    for vn in lst:\n",
    "        vrst[vn] = selectStationaySeries3(df1[vn], vn, marks)\n",
    "    vrdata = vrst.reset_index().fillna(value = 0) \n",
    "    return(vrdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "02887d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_val(gamma1,marks,vrdata):\n",
    "    tmp = pd.DataFrame([], columns = marks['Variable Names'].values)\n",
    "    for key in DataFrameDict_Hsa4.keys(): \n",
    "        df = HILDAvarExt(key,marks)\n",
    "        df1= df[vrdata.columns.tolist()]\n",
    "        df2 = df1.drop(df1.columns[0], axis=1)\n",
    "        \n",
    "        vrdata1 = vrdata.drop(vrdata.columns[0],axis=1)\n",
    "        vrdata2= vrdata1.apply(lambda x: x*gamma1)\n",
    "        \n",
    "        df_add = df2.add(vrdata2, fill_value=0)\n",
    "        tmp = pd.concat([tmp, df_add],axis = 0)\n",
    "        \n",
    "    pca = PCA()\n",
    "    X_train = tmp\n",
    "    scaler = StandardScaler()\n",
    "    X_train_std = scaler.fit_transform(X_train)\n",
    "\n",
    "    pca.fit(X_train_std)\n",
    "    cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "    d2 = np.argmax(cumsum >= 0.9) + 1\n",
    "\n",
    "\n",
    "    pca_d_sa4 = PCA(n_components=d2)\n",
    "    pca_d_sa4.fit(X_train_std)\n",
    "    X_pca_d_sa4 = pca_d_sa4.transform(X_train_std)\n",
    "\n",
    "    PCnames = []\n",
    "    for i in range(1, d2 + 1, 1):\n",
    "        PCnames.append(f\"sa4PC{i}\")\n",
    "    \n",
    "    pcadf = pd.DataFrame(X_pca_d_sa4, columns=PCnames)\n",
    "    pcadf_sa4_date = pcadf\n",
    "    return  d2, pca_d_sa4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7539d8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def person_cat_all(lst):\n",
    "    df_tmp = pd.DataFrame([], columns=lst)\n",
    "    for key in DataFrameDict_HILDA.keys():\n",
    "        lst0 = list(set(lst) - set(DataFrameDict_HILDAp[key].columns))\n",
    "        lst1 = list(set(lst) - set(lst0))\n",
    "        df = (\n",
    "            DataFrameDict_HILDAp[key][lst1]\n",
    "            .astype(str)\n",
    "        )\n",
    "        df[\"date\"] = str(key)\n",
    "        df_tmp = pd.concat([df_tmp, df], axis=0, ignore_index=True)\n",
    "    df_dummy = pd.get_dummies(df_tmp, columns=df_tmp.columns[:-1], dummy_na=True)\n",
    "    dfHILDA = df_dummy.groupby(\"date\").mean().reset_index()\n",
    "    return nan_dum(dfHILDA)\n",
    "def house_cat_all(lst):\n",
    "    df_tmp = pd.DataFrame([], columns=lst)\n",
    "    for key in DataFrameDict_HILDA.keys():\n",
    "        lst0 = list(set(lst) - set(DataFrameDict_HILDA[key].columns))\n",
    "        lst1 = list(set(lst) - set(lst0))\n",
    "        df = (\n",
    "            DataFrameDict_HILDA[key][lst1].astype(str)\n",
    "        )\n",
    "        df[\"date\"] = str(key)\n",
    "        df_tmp = pd.concat([df_tmp, df], axis=0, ignore_index=True)\n",
    "    df_dummy = pd.get_dummies(df_tmp, columns=df_tmp.columns[:-1], dummy_na=True)\n",
    "    dfHILDA = df_dummy.groupby(\"date\").mean().reset_index()\n",
    "    return nan_dum(dfHILDA)\n",
    "def person_num_all(lst):\n",
    "    df_tmp = pd.DataFrame([], columns=lst)\n",
    "    for key in DataFrameDict_HILDA.keys():\n",
    "        lst0 = list(set(lst) - set(DataFrameDict_HILDAp[key].columns))\n",
    "        lst1 = list(set(lst) - set(lst0))\n",
    "        df = DataFrameDict_HILDAp[key][lst1]\n",
    "        df[\"date\"] = str(key)\n",
    "        df_tmp = pd.concat([df_tmp, df], axis=0, ignore_index=True)\n",
    "    dfHILDA = df_tmp.groupby(\"date\").agg({lambda x: x.mean(skipna=False)})\n",
    "    dfHILDA.columns = lst\n",
    "    return dfHILDA.reset_index()\n",
    "def house_num_all(lst):\n",
    "    df_tmp = pd.DataFrame([], columns=lst)\n",
    "    for key in DataFrameDict_HILDA.keys():\n",
    "        lst0 = list(set(lst) - set(DataFrameDict_HILDA[key].columns))\n",
    "        lst1 = list(set(lst) - set(lst0))\n",
    "        df = DataFrameDict_HILDA[key][lst1]\n",
    "        df[\"date\"] = str(key)\n",
    "        df_tmp = pd.concat([df_tmp, df], axis=0, ignore_index=True)\n",
    "    dfHILDA = df_tmp.groupby(\"date\").agg({lambda x: x.mean(skipna=False)})\n",
    "    dfHILDA.columns = lst\n",
    "    return dfHILDA.reset_index()\n",
    "def HILDAext_cat_all(lst1, lst2):\n",
    "    dfHILDA1 = house_cat_all( lst1)\n",
    "    dfHILDA1[\"date\"] = pd.to_datetime(dfHILDA1[\"date\"]) + pd.offsets.YearEnd()\n",
    "    dfHILDA2 = person_cat_all(lst2)\n",
    "    dfHILDA2[\"date\"] = pd.to_datetime(dfHILDA2[\"date\"]) + pd.offsets.YearEnd()\n",
    "    dfHILDA = pd.merge(dfHILDA1, dfHILDA2, on=\"date\", how=\"left\")\n",
    "    return dfHILDA\n",
    "def HILDAext_num_all( lst1, lst2):\n",
    "    dfHILDA1 = house_num_all(lst1)\n",
    "    dfHILDA1[\"date\"] = pd.to_datetime(dfHILDA1[\"date\"]) + pd.offsets.YearEnd()\n",
    "    dfHILDA2 = person_num_all(lst2)\n",
    "    dfHILDA2[\"date\"] = pd.to_datetime(dfHILDA2[\"date\"]) + pd.offsets.YearEnd()\n",
    "    dfHILDA = pd.merge(dfHILDA1, dfHILDA2, on=\"date\", how=\"left\")\n",
    "    return dfHILDA\n",
    "lst_age = [f'hgdob{i}' for i in range(1, 21)]\n",
    "def HILDAext_age_all():    \n",
    "    df_tmp = pd.DataFrame()\n",
    "    for key in DataFrameDict_HILDA.keys():\n",
    "        df = DataFrameDict_HILDA[key][lst_age]\n",
    "        df[\"date\"] = str(key)\n",
    "        df = df.melt(id_vars='date', var_name='Indicator name', value_name='birth_date').sort_values('date', ascending=False).reset_index(drop=True)\n",
    "        df['birthDate'] = pd.to_datetime(df['birth_date'].replace(r'-','na',regex=True),errors = 'coerce')\n",
    "        df['year'] = pd.DatetimeIndex(df['birthDate']).year\n",
    "        df['age'] = key +1 - df['year']\n",
    "        df_tmp = pd.concat([df_tmp, df[['date','age']]], axis=0, ignore_index=True)\n",
    "    f = {'age': ['median', 'std', q1, q3,'count']} \n",
    "    dfHILDAage = df_tmp.groupby('date').agg(f)\n",
    "    dfHILDAage = dfHILDAage.set_axis(dfHILDAage.columns.map(''.join), axis=1, inplace=False).reset_index()\n",
    "    dfHILDAage[\"date\"] = pd.to_datetime(dfHILDAage[\"date\"]) + pd.offsets.YearEnd()\n",
    "    return dfHILDAage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "86e4ebd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('dfHILDA_cut.pickle', 'wb') as f:\n",
    "#     pickle.dump(dfHILDA_cut, f)\n",
    "with open('dfHILDA_cut.pickle', 'rb') as f:\n",
    "      dfHILDA_cut =  pickle.load(f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "886a7c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dfHILDA.pickle', 'rb') as f:\n",
    "      dfHILDA =  pickle.load(f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "681e96cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s1/vpd2prqd5fsc16qqsymrc9b00000gn/T/ipykernel_44206/2492502714.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_marks = df_marks.append(new_row, ignore_index=True)\n",
      "/var/folders/s1/vpd2prqd5fsc16qqsymrc9b00000gn/T/ipykernel_44206/2492502714.py:33: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_marks = df_marks.append(new_row, ignore_index=True)\n",
      "/var/folders/s1/vpd2prqd5fsc16qqsymrc9b00000gn/T/ipykernel_44206/2492502714.py:33: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_marks = df_marks.append(new_row, ignore_index=True)\n",
      "/var/folders/s1/vpd2prqd5fsc16qqsymrc9b00000gn/T/ipykernel_44206/2492502714.py:33: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_marks = df_marks.append(new_row, ignore_index=True)\n",
      "/var/folders/s1/vpd2prqd5fsc16qqsymrc9b00000gn/T/ipykernel_44206/2492502714.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_marks = df_marks.append(new_row, ignore_index=True)\n",
      "/var/folders/s1/vpd2prqd5fsc16qqsymrc9b00000gn/T/ipykernel_44206/2492502714.py:33: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_marks = df_marks.append(new_row, ignore_index=True)\n",
      "/var/folders/s1/vpd2prqd5fsc16qqsymrc9b00000gn/T/ipykernel_44206/2492502714.py:33: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_marks = df_marks.append(new_row, ignore_index=True)\n",
      "/var/folders/s1/vpd2prqd5fsc16qqsymrc9b00000gn/T/ipykernel_44206/2492502714.py:33: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_marks = df_marks.append(new_row, ignore_index=True)\n",
      "/var/folders/s1/vpd2prqd5fsc16qqsymrc9b00000gn/T/ipykernel_44206/2492502714.py:33: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_marks = df_marks.append(new_row, ignore_index=True)\n",
      "/var/folders/s1/vpd2prqd5fsc16qqsymrc9b00000gn/T/ipykernel_44206/2492502714.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_marks = df_marks.append(new_row, ignore_index=True)\n",
      "/var/folders/s1/vpd2prqd5fsc16qqsymrc9b00000gn/T/ipykernel_44206/2492502714.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_marks = df_marks.append(new_row, ignore_index=True)\n",
      "/var/folders/s1/vpd2prqd5fsc16qqsymrc9b00000gn/T/ipykernel_44206/2492502714.py:33: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_marks = df_marks.append(new_row, ignore_index=True)\n",
      "/var/folders/s1/vpd2prqd5fsc16qqsymrc9b00000gn/T/ipykernel_44206/2492502714.py:33: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_marks = df_marks.append(new_row, ignore_index=True)\n",
      "/var/folders/s1/vpd2prqd5fsc16qqsymrc9b00000gn/T/ipykernel_44206/2492502714.py:33: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_marks = df_marks.append(new_row, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.01\n",
    "df = dfHILDA_cut.set_index(\"date\")\n",
    "df1 = df.resample(\"Y\").mean().iloc[:, :]\n",
    "vrst = pd.DataFrame([])\n",
    "\n",
    "# need a dataframe to writedown the way to stabilize all variables\n",
    "df_marks = pd.DataFrame([],columns=['Variable Names', 'Approach'])\n",
    "\n",
    "\n",
    "for vn in df1.columns.values[1:]:\n",
    "    \n",
    "    variable_tar = df1[vn]\n",
    "    \n",
    "    count1 = np.isinf(variable_tar.pct_change(1)).values.sum()\n",
    "    count2 = np.isinf(variable_tar.pct_change(1)).values.sum()\n",
    "    \n",
    "    if adfuller(variable_tar.interpolate(\"bfill\").interpolate(\"ffill\"))[1] < threshold:\n",
    "            stationary_variable = variable_tar.interpolate(\"bfill\").interpolate(\"ffill\")\n",
    "            suffix =  \"original\"\n",
    "            new_row = {'Variable Names': vn,'Approach': suffix}\n",
    "            df_marks = df_marks.append(new_row, ignore_index=True)\n",
    "            newseries = pd.DataFrame(stationary_variable)\n",
    "            vrst = pd.concat([vrst, newseries], axis=1)\n",
    "\n",
    "    \n",
    "    \n",
    "    elif count1 == 0:\n",
    "        try:\n",
    "            if adfuller(variable_tar.pct_change(1).interpolate(\"bfill\").interpolate(\"ffill\"))[1] < threshold:\n",
    "                stationary_variable = variable_tar.pct_change(1).interpolate(\"bfill\").interpolate(\"ffill\")\n",
    "                suffix = \"1storderdiff\"\n",
    "                new_row = {'Variable Names': vn,'Approach': suffix}\n",
    "                df_marks = df_marks.append(new_row, ignore_index=True)\n",
    "                newseries = pd.DataFrame(stationary_variable)\n",
    "                vrst = pd.concat([vrst, newseries], axis=1)\n",
    "\n",
    "        except np.linalg.LinAlgError as e1:\n",
    "            print('except:', e1)\n",
    "    \n",
    "    \n",
    "    elif count2 == 0:\n",
    "        try: \n",
    "            if adfuller(variable_tar.pct_change(1).diff().dropna(how=\"all\"))[1] < threshold:\n",
    "                stationary_variable = variable_tar.pct_change(1).diff().dropna(how=\"all\")\n",
    "                suffix = \"2ndorderdiff\"\n",
    "                new_row = {'Variable Names': vn,'Approach': suffix}\n",
    "                df_marks = df_marks.append(new_row, ignore_index=True)\n",
    "                newseries = pd.DataFrame(stationary_variable)\n",
    "                vrst = pd.concat([vrst, newseries], axis=1)\n",
    "\n",
    "        except np.linalg.LinAlgError as e1:\n",
    "            print('except:', e1)     \n",
    "    \n",
    "    else:\n",
    "        print('not found')\n",
    "\n",
    "    \n",
    "    \n",
    "vrdata = vrst.reset_index()\n",
    "    \n",
    "pca = PCA()\n",
    "X_train = vrdata.loc[:, vrdata.columns != \"date\"]\n",
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "\n",
    "pca.fit(X_train_std)\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "d2 = np.argmax(cumsum >= 0.9) + 1\n",
    "print(d2)\n",
    "\n",
    "pca_d_sa4 = PCA(n_components=d2)\n",
    "pca_d_sa4.fit(X_train_std)\n",
    "X_pca_d_sa4 = pca_d_sa4.transform(X_train_std)\n",
    "\n",
    "PCnames = []\n",
    "for i in range(1, d2 + 1, 1):\n",
    "    PCnames.append(f\"sa4PC{i}\")\n",
    "    \n",
    "pcadf = pd.DataFrame(X_pca_d_sa4, columns=PCnames)\n",
    "pcadf['date'] = dfHILDA['date']  \n",
    "pcadf[\"date\"] = pd.to_datetime(pcadf[\"date\"]) - pd.offsets.MonthEnd(6)\n",
    "pcadf_sa4_date = pcadf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a9f722dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sa4PC1</th>\n",
       "      <th>sa4PC2</th>\n",
       "      <th>sa4PC3</th>\n",
       "      <th>sa4PC4</th>\n",
       "      <th>sa4PC5</th>\n",
       "      <th>sa4PC6</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.550736</td>\n",
       "      <td>4.001405</td>\n",
       "      <td>-0.188887</td>\n",
       "      <td>0.702175</td>\n",
       "      <td>0.082950</td>\n",
       "      <td>0.705940</td>\n",
       "      <td>2001-06-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.311801</td>\n",
       "      <td>3.042922</td>\n",
       "      <td>-0.298698</td>\n",
       "      <td>0.478824</td>\n",
       "      <td>-0.056509</td>\n",
       "      <td>0.621735</td>\n",
       "      <td>2002-06-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.940258</td>\n",
       "      <td>1.558986</td>\n",
       "      <td>2.363045</td>\n",
       "      <td>-2.075545</td>\n",
       "      <td>1.574217</td>\n",
       "      <td>-0.968113</td>\n",
       "      <td>2003-06-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.057147</td>\n",
       "      <td>0.898313</td>\n",
       "      <td>-0.442693</td>\n",
       "      <td>0.505976</td>\n",
       "      <td>-0.928006</td>\n",
       "      <td>-1.294751</td>\n",
       "      <td>2004-06-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.894035</td>\n",
       "      <td>0.283664</td>\n",
       "      <td>0.351091</td>\n",
       "      <td>2.571464</td>\n",
       "      <td>0.152391</td>\n",
       "      <td>0.574823</td>\n",
       "      <td>2005-06-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.218458</td>\n",
       "      <td>-0.814166</td>\n",
       "      <td>0.832698</td>\n",
       "      <td>0.406326</td>\n",
       "      <td>-0.886287</td>\n",
       "      <td>-0.508086</td>\n",
       "      <td>2006-06-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.920778</td>\n",
       "      <td>-1.816295</td>\n",
       "      <td>1.410426</td>\n",
       "      <td>0.311656</td>\n",
       "      <td>0.151475</td>\n",
       "      <td>-0.327882</td>\n",
       "      <td>2007-06-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.233330</td>\n",
       "      <td>-1.246341</td>\n",
       "      <td>0.581850</td>\n",
       "      <td>1.785910</td>\n",
       "      <td>-0.047347</td>\n",
       "      <td>-1.159676</td>\n",
       "      <td>2008-06-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.090411</td>\n",
       "      <td>-1.254053</td>\n",
       "      <td>1.929751</td>\n",
       "      <td>-0.327916</td>\n",
       "      <td>-0.638792</td>\n",
       "      <td>-0.175181</td>\n",
       "      <td>2009-06-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.459637</td>\n",
       "      <td>-0.676281</td>\n",
       "      <td>1.395833</td>\n",
       "      <td>-0.284119</td>\n",
       "      <td>-1.173002</td>\n",
       "      <td>0.878372</td>\n",
       "      <td>2010-06-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9.533841</td>\n",
       "      <td>3.216664</td>\n",
       "      <td>0.604128</td>\n",
       "      <td>-0.217388</td>\n",
       "      <td>-0.112564</td>\n",
       "      <td>-0.043492</td>\n",
       "      <td>2011-06-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.254969</td>\n",
       "      <td>0.210498</td>\n",
       "      <td>0.287577</td>\n",
       "      <td>-0.776167</td>\n",
       "      <td>0.495866</td>\n",
       "      <td>1.421148</td>\n",
       "      <td>2012-06-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.629847</td>\n",
       "      <td>0.674504</td>\n",
       "      <td>-1.376716</td>\n",
       "      <td>-0.845996</td>\n",
       "      <td>-0.408395</td>\n",
       "      <td>-0.658319</td>\n",
       "      <td>2013-06-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.073391</td>\n",
       "      <td>0.344283</td>\n",
       "      <td>-1.856535</td>\n",
       "      <td>-0.360524</td>\n",
       "      <td>-0.650197</td>\n",
       "      <td>-0.243160</td>\n",
       "      <td>2014-06-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.147162</td>\n",
       "      <td>-0.124803</td>\n",
       "      <td>-1.837179</td>\n",
       "      <td>0.370193</td>\n",
       "      <td>1.309613</td>\n",
       "      <td>-0.818224</td>\n",
       "      <td>2015-06-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.297871</td>\n",
       "      <td>-0.576408</td>\n",
       "      <td>-1.492036</td>\n",
       "      <td>-1.046725</td>\n",
       "      <td>0.406940</td>\n",
       "      <td>-0.041593</td>\n",
       "      <td>2016-06-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.420158</td>\n",
       "      <td>-1.848270</td>\n",
       "      <td>-0.952035</td>\n",
       "      <td>-0.716243</td>\n",
       "      <td>0.035479</td>\n",
       "      <td>0.069379</td>\n",
       "      <td>2017-06-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.015451</td>\n",
       "      <td>-2.469607</td>\n",
       "      <td>-0.208959</td>\n",
       "      <td>1.063566</td>\n",
       "      <td>1.844382</td>\n",
       "      <td>0.643041</td>\n",
       "      <td>2018-06-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.680533</td>\n",
       "      <td>-1.559615</td>\n",
       "      <td>-0.798238</td>\n",
       "      <td>-0.855630</td>\n",
       "      <td>-0.960038</td>\n",
       "      <td>0.400795</td>\n",
       "      <td>2019-06-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.104231</td>\n",
       "      <td>-1.845399</td>\n",
       "      <td>-0.304423</td>\n",
       "      <td>-0.689837</td>\n",
       "      <td>-0.192178</td>\n",
       "      <td>0.923242</td>\n",
       "      <td>2020-06-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sa4PC1    sa4PC2    sa4PC3    sa4PC4    sa4PC5    sa4PC6       date\n",
       "0  -3.550736  4.001405 -0.188887  0.702175  0.082950  0.705940 2001-06-30\n",
       "1  -3.311801  3.042922 -0.298698  0.478824 -0.056509  0.621735 2002-06-30\n",
       "2  -1.940258  1.558986  2.363045 -2.075545  1.574217 -0.968113 2003-06-30\n",
       "3  -1.057147  0.898313 -0.442693  0.505976 -0.928006 -1.294751 2004-06-30\n",
       "4   0.894035  0.283664  0.351091  2.571464  0.152391  0.574823 2005-06-30\n",
       "5  -1.218458 -0.814166  0.832698  0.406326 -0.886287 -0.508086 2006-06-30\n",
       "6  -0.920778 -1.816295  1.410426  0.311656  0.151475 -0.327882 2007-06-30\n",
       "7   0.233330 -1.246341  0.581850  1.785910 -0.047347 -1.159676 2008-06-30\n",
       "8   0.090411 -1.254053  1.929751 -0.327916 -0.638792 -0.175181 2009-06-30\n",
       "9  -0.459637 -0.676281  1.395833 -0.284119 -1.173002  0.878372 2010-06-30\n",
       "10  9.533841  3.216664  0.604128 -0.217388 -0.112564 -0.043492 2011-06-30\n",
       "11 -0.254969  0.210498  0.287577 -0.776167  0.495866  1.421148 2012-06-30\n",
       "12 -0.629847  0.674504 -1.376716 -0.845996 -0.408395 -0.658319 2013-06-30\n",
       "13 -0.073391  0.344283 -1.856535 -0.360524 -0.650197 -0.243160 2014-06-30\n",
       "14  0.147162 -0.124803 -1.837179  0.370193  1.309613 -0.818224 2015-06-30\n",
       "15  0.297871 -0.576408 -1.492036 -1.046725  0.406940 -0.041593 2016-06-30\n",
       "16  0.420158 -1.848270 -0.952035 -0.716243  0.035479  0.069379 2017-06-30\n",
       "17  1.015451 -2.469607 -0.208959  1.063566  1.844382  0.643041 2018-06-30\n",
       "18  0.680533 -1.559615 -0.798238 -0.855630 -0.960038  0.400795 2019-06-30\n",
       "19  0.104231 -1.845399 -0.304423 -0.689837 -0.192178  0.923242 2020-06-30"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcadf_sa4_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7e2e78e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "marks1 = df_marks['Variable Names'].loc[df_marks['Approach'] == 'original'].values\n",
    "marks2 = df_marks['Variable Names'].loc[df_marks['Approach'] == \"1storderdiff\"].values\n",
    "marks3 = df_marks['Variable Names'].loc[df_marks['Approach'] == \"2ndorderdiff\"].values\n",
    "def selectStationaySeries3(variable_tar, vn, marks):\n",
    "    \n",
    "    count1 = np.isinf(variable_tar.pct_change(1)).values.sum()\n",
    "    count2 = np.isinf(variable_tar.pct_change(1)).values.sum()\n",
    "    marks1 =marks['Variable Names'].loc[marks['Approach'] == 'original'].values\n",
    "    marks2 =marks['Variable Names'].loc[marks['Approach'] == \"1storderdiff\"].values\n",
    "    marks3 =marks['Variable Names'].loc[marks['Approach'] == \"2ndorderdiff\"].values\n",
    "    \n",
    "    if vn in marks1:\n",
    "            stationary_variable = variable_tar.interpolate(\"bfill\").interpolate(\"ffill\")\n",
    "            suffix =  \"original\"\n",
    "            #print(suffix)\n",
    "            return(pd.DataFrame(stationary_variable))\n",
    "    \n",
    "    \n",
    "    elif count1 == 0 and vn in marks2:\n",
    "        try:\n",
    "            if adfuller(variable_tar.pct_change(1).interpolate(\"bfill\").interpolate(\"ffill\"))[1] < threshold:\n",
    "                stationary_variable = variable_tar.pct_change(1).interpolate(\"bfill\").interpolate(\"ffill\")\n",
    "                suffix = \"1storderdiff\"\n",
    "                #print(suffix)\n",
    "                return(pd.DataFrame(stationary_variable))\n",
    "        except np.linalg.LinAlgError as e1:\n",
    "            print('except:', e1)\n",
    "    \n",
    "    \n",
    "    elif count2 == 0 and vn in marks3:\n",
    "        try: \n",
    "            if adfuller(variable_tar.pct_change(1).diff().dropna(how=\"all\"))[1] < threshold:\n",
    "                stationary_variable = variable_tar.pct_change(1).diff().dropna(how=\"all\")\n",
    "                suffix = \"2ndorderdiff\"\n",
    "                #print(suffix)\n",
    "                return(pd.DataFrame(stationary_variable))\n",
    "        except np.linalg.LinAlgError as e1:\n",
    "            print('except:', e1)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f77a2d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HILDA2PCsa4(key, marks):\n",
    "    df = DataFrameDict_Hsa4[key].interpolate(\"bfill\").interpolate(\"ffill\")\n",
    "    df = df.set_index(\"date\")\n",
    "    df1 = df.resample(\"Y\").mean().iloc[:, :]\n",
    "    \n",
    "    vrst = pd.DataFrame([])\n",
    "    for vn in df1.columns.values[1:]:\n",
    "        vrst = pd.concat([vrst, selectStationaySeries3(df1[vn], vn, marks)], axis=1)\n",
    "    vrdata = vrst.reset_index()\n",
    "    \n",
    "    pca = PCA()\n",
    "    X_train = vrdata.loc[:, vrdata.columns != \"date\"]\n",
    "    scaler = StandardScaler()\n",
    "    X_train_std = scaler.fit_transform(X_train)\n",
    "\n",
    "    pca.fit(X_train_std)\n",
    "    cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "    d = np.argmax(cumsum >= 0.9) + 1\n",
    "    print(d)\n",
    "\n",
    "    pca_d = PCA(n_components=d)\n",
    "    pca_d.fit(X_train_std)\n",
    "    X_pca_d = pca_d.transform(X_train_std)\n",
    "    PCnames = []\n",
    "    for i in range(1, d + 1, 1):\n",
    "        PCnames.append(f\"sa4PC{i}\")\n",
    "    pcadf = pd.DataFrame(X_pca_d, columns=PCnames)\n",
    "    pcadf['date'] = DataFrameDict_Hsa4[key]['date']  \n",
    "    pcadf[\"date\"] = pd.to_datetime(pcadf[\"date\"]) - pd.offsets.MonthEnd(6)\n",
    "    pcadf[\"date\"] = pcadf[\"date\"]\n",
    "    return pcadf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ca9ab540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HILDAvarExt(key, marks):\n",
    "    df = DataFrameDict_Hsa4[key].interpolate(\"bfill\").interpolate(\"ffill\")\n",
    "    df = df.set_index(\"date\")\n",
    "    df1 = df.resample(\"Y\").mean().iloc[:, :]\n",
    "    vrst = pd.DataFrame([], columns = df_marks['Variable Names'].values)\n",
    "    lst = list( set(df_marks['Variable Names'].values) & set(df1.columns.values[1:]))\n",
    "    for vn in lst:\n",
    "        vrst[vn] = selectStationaySeries3(df1[vn], vn, marks)\n",
    "    vrdata = vrst.reset_index().fillna(value = 0) \n",
    "    return(vrdata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8e85f0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_val(gamma1,marks,vrdata):\n",
    "    tmp = pd.DataFrame([], columns = marks['Variable Names'].values)\n",
    "    for key in DataFrameDict_Hsa4.keys(): \n",
    "        df = HILDAvarExt(key,marks)\n",
    "        df1= df[vrdata.columns.tolist()]\n",
    "        df2 = df1.drop(df1.columns[0], axis=1)\n",
    "        \n",
    "        vrdata1 = vrdata.drop(vrdata.columns[0],axis=1)\n",
    "        vrdata2= vrdata1.apply(lambda x: x*gamma1)\n",
    "        \n",
    "        df_add = df2.add(vrdata2, fill_value=0)\n",
    "        tmp = pd.concat([tmp, df_add],axis = 0)\n",
    "        \n",
    "    pca = PCA()\n",
    "    X_train = tmp\n",
    "    scaler = StandardScaler()\n",
    "    X_train_std = scaler.fit_transform(X_train)\n",
    "\n",
    "    pca.fit(X_train_std)\n",
    "    cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "    d2 = np.argmax(cumsum >= 0.9) + 1\n",
    "\n",
    "\n",
    "    pca_d_sa4 = PCA(n_components=d2)\n",
    "    pca_d_sa4.fit(X_train_std)\n",
    "    X_pca_d_sa4 = pca_d_sa4.transform(X_train_std)\n",
    "\n",
    "    PCnames = []\n",
    "    for i in range(1, d2 + 1, 1):\n",
    "        PCnames.append(f\"sa4PC{i}\")\n",
    "    \n",
    "    pcadf = pd.DataFrame(X_pca_d_sa4, columns=PCnames)\n",
    "    pcadf_sa4_date = pcadf\n",
    "    return  d2, pca_d_sa4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "028b04b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCnumbers = []\n",
    "# x = range(0,100,1)\n",
    "# for gamma in x:\n",
    "#     gamma1 = gamma\n",
    "#     d2, pcafit = PCA_val(gamma1,df_marks,vrdata)\n",
    "#     PCnumbers.append(d2)\n",
    "#     print(gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f506e6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = range(0,100,1)\n",
    "PCnumbers= [12, 12, 11, 11, 11, 10, 10, 10, 10, 10, 9, 9, 9, 9, 9, 9, 9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b20e523e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.]),\n",
       " [Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, '')])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.interpolate import make_interp_spline, BSpline\n",
    "# represents number of points to make between x.min and x.max\n",
    "xnew =np.linspace(0, 100, 100)\n",
    "spl = make_interp_spline(x, PCnumbers, k=1)  # type: BSpline\n",
    "PCno_smooth = spl(xnew)\n",
    "\n",
    "color1 = \"#0085c3\"\n",
    "color2 = \"#7ab800\"\n",
    "color3 = \"#dc5034\"\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.step(x, PCnumbers,where='post',color = color3)\n",
    "ax.grid(ls=\":\", color=\"gray\", alpha=0.6)\n",
    "\n",
    "plt.xlabel(r'$\\gamma$')\n",
    "plt.ylabel('Number of risk factors at the SA4s level')\n",
    "\n",
    "plt.xticks(rotation=45, fontsize=12)\n",
    "plt.yticks(fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "70329d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "gammaindexList = []\n",
    "for i in range(12,6,-1):\n",
    "   aa = min([index for index,value in enumerate(PCnumbers) if int(value)  == i])\n",
    "   gammaindexList.append(aa)\n",
    "gammaList = np.linspace(0, 100, 100)[gammaindexList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "fa02a0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcadf['date'] = dfHILDA['date']  \n",
    "pcadf[\"date\"] = pd.to_datetime(pcadf[\"date\"]) - pd.offsets.MonthEnd(6)\n",
    "pcadf_sa4_date_new = pcadf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8d4608c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s1/vpd2prqd5fsc16qqsymrc9b00000gn/T/ipykernel_44206/3122983395.py:84: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  macvar = macvar.set_axis(\n",
      "/var/folders/s1/vpd2prqd5fsc16qqsymrc9b00000gn/T/ipykernel_44206/3122983395.py:125: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  matrixmac = macvarsta.corr().round(2)\n"
     ]
    }
   ],
   "source": [
    "xls1 = pd.read_excel(\"f01hist.xls\", sheet_name=\"Data\", header=2)\n",
    "xls1 = xls1.drop(xls1.index[0:8], axis=0)\n",
    "xls1[\"Description\"] = pd.to_datetime(xls1[\"Description\"])\n",
    "xls1[\"Description\"] = xls1[\"Description\"].dt.date.apply(lambda x: x.strftime(\"%Y-%m\"))\n",
    "xls3 = pd.read_excel(\"f11hist-1969-2009.xls\", sheet_name=\"Data\", header=2)\n",
    "xls3 = xls3.drop(xls3.index[0:8], axis=0)\n",
    "xls3[\"Description\"] = pd.to_datetime(xls3[\"Description\"])\n",
    "xls3[\"Description\"] = xls3[\"Description\"].dt.date.apply(lambda x: x.strftime(\"%Y-%m\"))\n",
    "xls4 = pd.read_excel(\"f11hist.xls\", sheet_name=\"Data\", header=2)\n",
    "xls4 = xls4.drop(xls4.index[0:8], axis=0)\n",
    "xls4[\"Description\"] = pd.to_datetime(xls4[\"Description\"])\n",
    "xls4[\"Description\"] = xls4[\"Description\"].dt.date.apply(lambda x: x.strftime(\"%Y-%m\"))\n",
    "xls34 = pd.concat([xls3, xls4], axis=0)\n",
    "xls5 = pd.read_excel(\"g01hist.xls\", sheet_name=\"Data\", header=2)\n",
    "xls5 = xls5.drop(xls5.index[0:8], axis=0)\n",
    "xls5[\"Description\"] = pd.to_datetime(xls5[\"Description\"])\n",
    "xls5[\"Description\"] = xls5[\"Description\"].dt.date.apply(lambda x: x.strftime(\"%Y-%m\"))\n",
    "xls6 = pd.read_excel(\"h01hist.xls\", sheet_name=\"Data\", header=2)\n",
    "xls6 = xls6.drop(xls6.index[0:8], axis=0)\n",
    "xls6[\"Description\"] = pd.to_datetime(xls6[\"Description\"])\n",
    "xls6[\"Description\"] = xls6[\"Description\"].dt.date.apply(lambda x: x.strftime(\"%Y-%m\"))\n",
    "xls7 = pd.read_excel(\"h03hist.xls\", sheet_name=\"Data\", header=2)\n",
    "xls7 = xls7.drop(xls7.index[0:8], axis=0)\n",
    "xls7[\"Description\"] = pd.to_datetime(xls7[\"Description\"])\n",
    "xls7[\"Description\"] = xls7[\"Description\"].dt.date.apply(lambda x: x.strftime(\"%Y-%m\"))\n",
    "# Download ASX data from Yahoo Finance\n",
    "\n",
    "ASX200data = yf.download('^AXJO', start='1999-01-01', end='2021-06-01', interval = \"1mo\", progress=False)\n",
    "ASX200data = ASX200data.reset_index()\n",
    "ASX200data[\"Description\"] = pd.to_datetime(ASX200data[\"Date\"])\n",
    "ASX200data[\"Description\"] = ASX200data[\"Description\"].dt.date.apply(lambda x: x.strftime(\"%Y-%m\"))\n",
    "\n",
    "macvar = pd.DataFrame().assign(\n",
    "    Description=xls7.loc[\n",
    "        (\"2021-06\" > xls7[\"Description\"]) & (xls7[\"Description\"] > \"1998-12\")\n",
    "    ][\"Description\"]\n",
    ")\n",
    "macvar.reset_index(drop=True, inplace=True)\n",
    "\n",
    "macvar = pd.merge(\n",
    "    macvar,\n",
    "    xls1[[\"Description\", \"Cash Rate Target; monthly average\"]],\n",
    "    on=\"Description\",\n",
    "    how=\"left\",\n",
    ")\n",
    "macvar = pd.merge(\n",
    "    macvar,\n",
    "    xls34[[\"Description\", \"AUD/USD Exchange Rate; see notes for further detail.\"]],\n",
    "    on=\"Description\",\n",
    "    how=\"left\",\n",
    ")\n",
    "macvar = pd.merge(\n",
    "    macvar,\n",
    "    xls5[[\"Description\", \"Consumer price index; All groups\"]],\n",
    "    on=\"Description\",\n",
    "    how=\"left\",\n",
    ")\n",
    "macvar = pd.merge(\n",
    "    macvar,\n",
    "    xls6[[\"Description\", \"Gross domestic product (GDP); Chain volume\"]],\n",
    "    on=\"Description\",\n",
    "    how=\"left\",\n",
    ")\n",
    "macvar = pd.merge(\n",
    "    macvar,\n",
    "    xls7[[\"Description\", \"Retail sales; All industries; Current price\"]],\n",
    "    on=\"Description\",\n",
    "    how=\"left\",\n",
    ")\n",
    "macvar = pd.merge(\n",
    "    macvar,\n",
    "    xls7[[\"Description\", \"Private dwelling approvals\"]],\n",
    "    on=\"Description\",\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "macvar = pd.merge(\n",
    "    macvar,\n",
    "    ASX200data[[\"Description\", \"Adj Close\"]],\n",
    "    on=\"Description\",\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "macvar = macvar.set_axis(\n",
    "    [\"date\", \"ir\", \"exr\", \"cpi\", \"gdp\", \"rs\", \"pda\", \"asx\"], axis=1, inplace=False\n",
    ")\n",
    "\n",
    "\n",
    "macvar[\"ir\"] = macvar[\"ir\"].astype(float, errors=\"raise\")\n",
    "macvar[\"exr\"] = macvar[\"exr\"].astype(float, errors=\"raise\")\n",
    "macvar[\"cpi\"] = macvar[\"cpi\"].astype(float, errors=\"raise\")\n",
    "macvar[\"gdp\"] = macvar[\"gdp\"].astype(float, errors=\"raise\")\n",
    "macvar[\"rs\"] = macvar[\"rs\"].astype(float, errors=\"raise\")\n",
    "macvar[\"pda\"] = macvar[\"pda\"].astype(float, errors=\"raise\")\n",
    "macvar[\"asx\"] = macvar[\"asx\"].astype(float, errors=\"raise\")\n",
    "macvar = macvar.interpolate()\n",
    "\n",
    "threshold = 0.01\n",
    "\n",
    "def selectStationaySeries(variable_tar):\n",
    "        if adfuller(variable_tar.dropna(how=\"all\"))[1] < threshold:\n",
    "            stationary_variable = variable_tar\n",
    "            suffix =  \"original\"\n",
    "        elif adfuller(variable_tar.pct_change(1).dropna(how=\"all\"))[1] < threshold:\n",
    "            stationary_variable = variable_tar.pct_change(1).dropna(how=\"all\")\n",
    "            suffix = \"1storderdiff\"\n",
    "        elif adfuller(variable_tar.pct_change(3).dropna(how=\"all\"))[1] < threshold:\n",
    "            stationary_variable = variable_tar.pct_change(3).dropna(how=\"all\")\n",
    "            suffix = \"seasonaldiff\"\n",
    "        elif adfuller(variable_tar.pct_change(12).dropna(how=\"all\"))[1] < threshold:\n",
    "            stationary_variable = variable_tar.pct_change(12).dropna(how=\"all\")\n",
    "            suffix = \"annualdiff\"     \n",
    "        elif adfuller(variable_tar.pct_change(1).diff().dropna(how=\"all\"))[1] < threshold:\n",
    "            stationary_variable = variable_tar.pct_change(1).diff().dropna(how=\"all\")\n",
    "            suffix = \"2ndorderdiff\"\n",
    "        else:\n",
    "            print(\"not found\")\n",
    "        return(pd.DataFrame(stationary_variable))\n",
    "    \n",
    "macvarst = macvar[\"date\"] \n",
    "for vn in macvar.columns.values[1:]:\n",
    "    macvarst = pd.concat([macvarst, selectStationaySeries(macvar[vn])], axis=1)\n",
    "\n",
    "macvarsta = macvarst  \n",
    "matrixmac = macvarsta.corr().round(2)\n",
    "macdata = macvarsta.loc[\n",
    "    (\"2020-01\" > macvarsta[\"date\"]) & (macvarsta[\"date\"] > \"1999-12\")\n",
    "]\n",
    "\n",
    "pca = PCA()\n",
    "X_train = macdata.loc[:, macdata.columns != \"date\"]\n",
    "poly= PolynomialFeatures(degree=2)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#X_train_poly = poly.fit_transform(X_train)\n",
    "#X_train_std = scaler.fit_transform(X_train_poly)\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "\n",
    "pca.fit(X_train_std)\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "d = np.argmax(cumsum >= 0.9) + 1\n",
    "print(d)\n",
    "\n",
    "pca_d = PCA(n_components=d)\n",
    "pca_d.fit(X_train_std)\n",
    "X_pca_d = pca_d.transform(X_train_std)\n",
    "PCnames = []\n",
    "for i in range(1, d + 1, 1):\n",
    "    PCnames.append(f\"PC{i}\")\n",
    "PC_nat = pd.DataFrame(X_pca_d, columns=PCnames)\n",
    "\n",
    "PC_nat['date'] = aveHPIdf_lv3.loc[(\"2020-01\" > aveHPIdf_lv3[\"date\"]) & (aveHPIdf_lv3[\"date\"] > \"2000-01\")].reset_index(drop= True)[\"date\"]\n",
    "PC_nat= PC_nat.set_index(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9912a299",
   "metadata": {},
   "outputs": [],
   "source": [
    "numcols = len(X_train_std[0])\n",
    "numrows = len(X_train_std)\n",
    "matrixones = np.ones((numrows, numcols))\n",
    "matrixdiag = np.diag(np.diag(np.ones((numcols, numcols))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "fc55f7ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.30415021, -0.04406333,  0.65239764, -0.14823615,  0.67093812,\n",
       "        -0.07877896],\n",
       "       [-0.61450737,  0.18722406, -0.113981  ,  0.15501654, -0.06064396,\n",
       "         0.67187603],\n",
       "       [-0.04087253,  0.66140468,  0.29336408,  0.03947194, -0.32647867,\n",
       "        -0.4136064 ],\n",
       "       [-0.19796307, -0.36187347,  0.45490099, -0.44273536, -0.63532613,\n",
       "         0.09614474],\n",
       "       [-0.29220424, -0.59925711, -0.14666126,  0.30274108, -0.04291215,\n",
       "        -0.43075913],\n",
       "       [-0.12221443,  0.06607772, -0.44896844, -0.81189832,  0.17509797,\n",
       "        -0.12736877],\n",
       "       [-0.62345306,  0.17641333, -0.21285224,  0.07478132, -0.05861721,\n",
       "        -0.40035757]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_d.transform(matrixdiag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "bced01f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_1_y = aveHPIdf_lv3.groupby([\"year\"])[\"logHPIdiff\"].agg([\"mean\"]).reset_index()\n",
    "avg_1_y=avg_1_y.rename(columns = {'mean':'l0'})\n",
    "avg_1_y['date'] = pd.to_datetime(avg_1_y['year'].apply(str)) + pd.offsets.YearEnd()\n",
    "avg_1_y = avg_1_y.set_index(\"date\")\n",
    "\n",
    "avg_1 = aveHPIdf_lv3.groupby([\"date\"])[\"logHPIdiff\"].agg([\"mean\"]).reset_index()\n",
    "avg_1 = avg_1.set_index(\"date\")\n",
    "avg_1=avg_1.rename(columns = {'mean':'l0'})\n",
    "\n",
    "avg_2 = aveHPIdf_lv3.groupby([\"state\",\"year\"])[\"logHPIdiff\"].agg([\"mean\"]).reset_index()\n",
    "avg_2['date'] = pd.to_datetime(avg_2['year'].apply(str)) + pd.offsets.YearEnd()\n",
    "avg_2 = avg_2.set_index(\"date\")\n",
    "\n",
    "avg_3 = aveHPIdf_lv3.groupby([\"sa4\",\"date\"])[\"logHPIdiff\"].agg([\"mean\"]).reset_index()\n",
    "avg_3=avg_3.rename(columns = {'mean':'l01'})\n",
    "\n",
    "\n",
    "avg_4 = aveHPIdf_lv3.groupby([\"postcode\",\"date\"])[\"logHPIdiff\"].agg([\"mean\"]).reset_index()\n",
    "avg_4=avg_4.rename(columns = {'mean':'l012'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "bab122ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " VAR Order Selection (* highlights the minimums)  \n",
      "==================================================\n",
      "       AIC         BIC         FPE         HQIC   \n",
      "--------------------------------------------------\n",
      "0       -1.447      -1.339      0.2352      -1.404\n",
      "1       -3.836     -2.967*     0.02158     -3.485*\n",
      "2       -3.989      -2.359     0.01855      -3.331\n",
      "3      -4.211*      -1.820    0.01491*      -3.245\n",
      "4       -4.021     -0.8691     0.01814      -2.748\n",
      "5       -3.879     0.03323     0.02112      -2.299\n",
      "6       -3.962      0.7110     0.01973      -2.075\n",
      "7       -3.837       1.597     0.02285      -1.642\n",
      "8       -3.726       2.468     0.02627      -1.224\n",
      "9       -3.745       3.210     0.02676     -0.9360\n",
      "10      -3.597       4.119     0.03257     -0.4800\n",
      "11      -3.526       4.951     0.03710     -0.1022\n",
      "12      -3.432       5.806     0.04387      0.2996\n",
      "--------------------------------------------------\n",
      "PC1 : 2.02\n",
      "PC2 : 2.01\n",
      "PC3 : 2.22\n",
      "PC4 : 2.05\n",
      "PC5 : 2.07\n",
      "PC6 : 2.0\n",
      "l0 : 1.53\n"
     ]
    }
   ],
   "source": [
    "agg = avg_1.reset_index()\n",
    "pcadf0 = PC_nat.reset_index()\n",
    "pcadf = pcadf0.loc[(\"2020-01\" > pcadf0[\"date\"]) & (pcadf0[\"date\"] > \"2000-11\")].reset_index(drop = True)\n",
    "\n",
    "\n",
    "values  = agg[\"l0\"].loc[(\"2020-01\" > agg[\"date\"]) & (agg[\"date\"] > \"2000-11\")].reset_index(drop=True).values\n",
    "values = values.reshape((len(values), 1))\n",
    "\n",
    "scaler1 = scaler.fit(values)\n",
    "normalized  = scaler1.transform(values)\n",
    "normalized_list =  [i[0] for i in normalized]\n",
    "normalized_df = pd.DataFrame(normalized_list,columns = ['l0'])\n",
    "\n",
    "pca_avg = pd.concat(\n",
    "    [\n",
    "        pcadf,\n",
    "        normalized_df,\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "\n",
    "df = pca_avg.iloc[:,1:]\n",
    "model = VAR(df)\n",
    "print(model.select_order(12).summary() )\n",
    "# lag order should be one here\n",
    "\n",
    "model_fitted = model.fit(1)\n",
    "model_fitted.summary()\n",
    "model_fitted_l0 =  model_fitted\n",
    "\n",
    "\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "out = durbin_watson(model_fitted.resid)\n",
    "\n",
    "\n",
    "for col, val in zip(df.columns, out):\n",
    "    print(col, \":\", round(val, 2))\n",
    "\n",
    "lag_order = model_fitted.k_ar\n",
    "forecast_input = df\n",
    "start_point = lag_order \n",
    "\n",
    "df_forecast = []\n",
    "for i in range(1,df.shape[0]-lag_order+1, 1):\n",
    "    forecast_input = df.values[\n",
    "        -lag_order + start_point + i - 1 : start_point + i - 1,\n",
    "    ]\n",
    "    df_forecast.append(\n",
    "        model_fitted.forecast(y=forecast_input, steps=1)[\n",
    "            0,\n",
    "        ][-1]\n",
    "    )\n",
    "    \n",
    "values_forecast = np.array(df_forecast)\n",
    "values_forecast = values_forecast.reshape((len(values_forecast), 1))\n",
    "inversed = scaler1.inverse_transform(values_forecast)\n",
    "inversed_list =  [i[0] for i in inversed]\n",
    "\n",
    "lag_order_l0 = lag_order\n",
    "start_point_l0 =  start_point\n",
    "std_l0 = pca_avg.iloc[:,1:].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0959aa6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0720768 , -0.01011618, -0.02574083,  0.03347487, -0.04343205,\n",
       "       -0.04924782])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fitted_l0.coefs[0][-1][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5a4e505b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Granger causality F-test. H_0: ['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6'] do not Granger-cause l0. Conclusion: reject H_0 at 5% significance level.</caption>\n",
       "<tr>\n",
       "  <th>Test statistic</th> <th>Critical value</th> <th>p-value</th>    <th>df</th>    \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>3.173</td>          <td>2.104</td>      <td>0.004</td>  <td>(6, 1547)</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fitted.test_causality('l0', ['PC1','PC2','PC3','PC4','PC5','PC6'], kind='f').summary()\n",
    "# Results: ['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6'] do Granger-cause l0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "16754a02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>normality (skew and kurtosis) test. H_0: data generated by normally-distributed process. Conclusion: reject H_0 at 5% significance level.</caption>\n",
       "<tr>\n",
       "  <th>Test statistic</th> <th>Critical value</th> <th>p-value</th> <th>df</th>\n",
       "</tr>\n",
       "<tr>\n",
       "       <td>404.8</td>          <td>23.68</td>      <td>0.000</td>  <td>14</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fitted.test_normality().summary()\n",
    "# Results: data is not generated by normally-distributed process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4a585c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VARMA\n",
    "# from statsmodels.tsa.statespace.varmax import VARMAX\n",
    "# VARMA_model_l0  = VARMAX(pca_avg.iloc[:,1:],order = (1,0))\n",
    "# VARMA_model_fit_l0 = VARMA_model_l0.fit(disp=False)\n",
    "# VARMA_model_fit_l0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "42598f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a2l.to_ltx(VARMA_model_fit_l0.coefficient_matrices_var[0], frmt = '{:6.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "816746ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# def create_upper_matrix(values, size):\n",
    "#     upper = np.zeros((size, size))\n",
    "#     upper[np.triu_indices(7, 0)] = values\n",
    "#     return(upper)\n",
    "# cov_l0 = create_upper_matrix(VARMA_model_fit_l0.params[-28:], 7)\n",
    "# a2l.to_ltx(cov_l0, frmt = '{:6.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d16162f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# irf_l0 = model_fitted_l0.irf(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9935eba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# irf_l0.plot(response = 'l0', plot_params = {'ncols':3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "83c97136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# irf_l0.plot_cum_effects(orth=False,figsize = (20,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8f12d24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pca_avg.iloc[:,1:]\n",
    "nobs = 28  # post-covid data is used as the test data set\n",
    "df_train, df_test = df[0:-nobs], df[-nobs:]\n",
    "# Check size\n",
    "start_point = df_train.shape[0]\n",
    "lag_order = model_fitted_l0.k_ar\n",
    "forecast_input = df_train.values[-lag_order:]\n",
    "\n",
    "df_forecast = []\n",
    "for i in range(1, nobs + 1, 1):\n",
    "    forecast_input = df.values[-lag_order + start_point + i - 1 : start_point + i - 1,]\n",
    "    df_forecast.append(\n",
    "        model_fitted_l0.forecast(y=forecast_input, steps=1)[\n",
    "            0,\n",
    "        ][-1]\n",
    "    )\n",
    "values_forecast = np.array(df_forecast)\n",
    "values_forecast = values_forecast.reshape((len(values_forecast), 1))\n",
    "inversed = scaler1.inverse_transform(values_forecast)\n",
    "inversed_list =  [i[0] for i in inversed]\n",
    "y = inversed_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ba00d126",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s1/vpd2prqd5fsc16qqsymrc9b00000gn/T/ipykernel_44206/771883143.py:5: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  df_plot['l0'] = agg['l0'].loc[(\"2020-01\" > agg[\"date\"]) & (agg[\"date\"] > \"2000-11\")][-nobs:].values\n"
     ]
    }
   ],
   "source": [
    "date_frame = pd.DataFrame(agg[\"date\"].loc[(\"2020-01\" > agg[\"date\"]) & (agg[\"date\"] > \"2001-01\")].reset_index(drop=True))\n",
    "x = date_frame[-nobs:][\"date\"]\n",
    "df_plot = pd.DataFrame({'date':x, 'l0_pred':y })\n",
    "y2 = agg[\"l0\"].loc[(\"2020-01\" > agg[\"date\"]) & (agg[\"date\"] > \"2000-11\")].reset_index(drop=True)[-nobs:]\n",
    "df_plot['l0'] = agg['l0'].loc[(\"2020-01\" > agg[\"date\"]) & (agg[\"date\"] > \"2000-11\")][-nobs:].values\n",
    "df_plot = df_plot.set_index('date',drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e5fcefef",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_1_pred = pd.DataFrame(inversed_list, columns=[\"l0_forecast\"])\n",
    "avg_1_pred['date'] = aveHPIdf_lv3.loc[(\"2020-01\" > aveHPIdf_lv3[\"date\"]) & (aveHPIdf_lv3[\"date\"] > \"2001-01\")].reset_index(drop= True)[\"date\"]    \n",
    "avg_1_pred  = avg_1_pred.set_index(\"date\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "27b8de81",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_whole = list(dfHILDA.columns)\n",
    "result_ancob = [i for i in lst_whole if i.startswith('ancob_')]\n",
    "list_ancob0 = ['1101', '2100', '1201', '7103', '5204', '6101', '9225', '5105', '2308']\n",
    "list_ancob =  ['ancob_' + sub for sub in list_ancob0]\n",
    "result_edhigh = [i for i in lst_whole if i.startswith('edhigh1_')]\n",
    "list_edhigh0= ['1','2','3','4','5','8','9']\n",
    "list_edhigh =  ['edhigh1_' + sub for sub in list_edhigh0]\n",
    "result_anatsi = [i for i in lst_whole if i.startswith('anatsi_')]\n",
    "list_anatsi0= ['1','2','3','4']\n",
    "list_anatsi =  ['anatsi_' + sub for sub in list_anatsi0]\n",
    "result_chkb =  [i for i in lst_whole if i.startswith('chkb12_')]\n",
    "list_chkb0= ['1','2','3','4']\n",
    "list_chkb =  ['chkb12_' + sub for sub in list_chkb0]\n",
    "list_deleted =  [i for i in lst_whole if i.startswith(('ancob_','edhigh1_','chkb12_','anatsi_'))]\n",
    "list_remained = [vn for vn in lst_whole if vn not in list_deleted]\n",
    "list_final = list_remained + list_ancob + list_edhigh + list_anatsi + list_chkb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1aa38d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gamma2AIC_VAR(key,pcafit,d3,lag):\n",
    "    Dictdf = DataFrameDict_Hsa4[key].interpolate(\"bfill\").interpolate(\"ffill\").loc[:, DataFrameDict_Hsa4[key].columns != \"date\"]\n",
    "    Xtraindata = pd.DataFrame([], columns = df_marks['Variable Names'].values)\n",
    "    lst = list(set(df_marks['Variable Names'].values) & set(Dictdf.columns.values))\n",
    "\n",
    "    for vn in lst:\n",
    "        Xtraindata[vn] = Dictdf[vn]\n",
    "    X_train = Xtraindata.reset_index(drop =True).fillna(value = 0)     \n",
    "    scaler = StandardScaler()\n",
    "\n",
    "# X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    X_train_std = scaler.fit_transform(X_train)\n",
    "    X_pca_d_sa4_new = pcafit.transform(X_train_std)\n",
    "\n",
    "    PCnames = []\n",
    "    for i in range(1, d3 + 1, 1):\n",
    "        PCnames.append(f\"sa4PC{i}\")  \n",
    "    \n",
    "    pcadf = pd.DataFrame(X_pca_d_sa4_new , columns=PCnames)\n",
    "    pcadf['date'] = avg_1_y.reset_index()['date'][1:21].reset_index(drop= True)\n",
    "    pcadf= pcadf.set_index(\"date\")    \n",
    "    \n",
    "    df1 = pd.concat([pcadf,avg_1['l0']], axis=1, join = \"outer\")\n",
    "    df2 = avg_3.loc[avg_3['sa4'] == key].set_index('date')\n",
    "    df3 = pd.concat([df1,df2['l01']], axis=1,join = \"outer\")\n",
    "#     df4 = df3.interpolate(method='linear').interpolate(method=\"spline\", order=1, limit_direction=\"both\")\n",
    "    df4 = df3.interpolate(\"bfill\").interpolate(\"ffill\")\n",
    "    df4['l1'] = df4['l01'] - df4['l0']\n",
    "    pcadf_sa4_date_new = df4.drop(['l01', 'l0'], axis=1)\n",
    "\n",
    "    modelsa4 = VAR(pcadf_sa4_date_new)\n",
    "    result = modelsa4.fit(lag)\n",
    "    #print(\"Lag Order =\", lag)\n",
    "    #print(\"AIC : \", result.aic)\n",
    "    return(result.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "885d78d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gamma2BIC_VAR(key,pcafit,d3,lag):\n",
    "    Dictdf = DataFrameDict_Hsa4[key].interpolate(\"bfill\").interpolate(\"ffill\").loc[:, DataFrameDict_Hsa4[key].columns != \"date\"]\n",
    "    Xtraindata = pd.DataFrame([], columns = df_marks['Variable Names'].values)\n",
    "    lst = list(set(df_marks['Variable Names'].values) & set(Dictdf.columns.values))\n",
    "\n",
    "    for vn in lst:\n",
    "        Xtraindata[vn] = Dictdf[vn]\n",
    "    X_train = Xtraindata.reset_index(drop =True).fillna(value = 0)     \n",
    "    scaler = StandardScaler()\n",
    "\n",
    "# X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    X_train_std = scaler.fit_transform(X_train)\n",
    "    X_pca_d_sa4_new = pcafit.transform(X_train_std)\n",
    "\n",
    "    PCnames = []\n",
    "    for i in range(1, d3 + 1, 1):\n",
    "        PCnames.append(f\"sa4PC{i}\")  \n",
    "    \n",
    "    pcadf = pd.DataFrame(X_pca_d_sa4_new , columns=PCnames)\n",
    "    pcadf['date'] = avg_1_y.reset_index()['date'][1:21].reset_index(drop= True)\n",
    "    pcadf= pcadf.set_index(\"date\")    \n",
    "    \n",
    "    df1 = pd.concat([pcadf,avg_1['l0']], axis=1, join = \"outer\")\n",
    "    df2 = avg_3.loc[avg_3['sa4'] == key].set_index('date')\n",
    "    df3 = pd.concat([df1,df2['l01']], axis=1,join = \"outer\")\n",
    "#     df4 = df3.interpolate(method='linear').interpolate(method=\"spline\", order=1, limit_direction=\"both\")\n",
    "    df4 = df3.interpolate(\"bfill\").interpolate(\"ffill\")\n",
    "    df4['l1'] = df4['l01'] - df4['l0']\n",
    "    pcadf_sa4_date_new = df4.drop(['l01', 'l0'], axis=1)\n",
    "\n",
    "    modelsa4 = VAR(pcadf_sa4_date_new)\n",
    "    result = modelsa4.fit(lag)\n",
    "    #print(\"Lag Order =\", lag)\n",
    "    #print(\"AIC : \", result.aic)\n",
    "    return(result.bic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ee73ccc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gamma2FPE_VAR(key,pcafit,d3,lag):\n",
    "    Dictdf = DataFrameDict_Hsa4[key].interpolate(\"bfill\").interpolate(\"ffill\").loc[:, DataFrameDict_Hsa4[key].columns != \"date\"]\n",
    "    Xtraindata = pd.DataFrame([], columns = df_marks['Variable Names'].values)\n",
    "    lst = list(set(df_marks['Variable Names'].values) & set(Dictdf.columns.values))\n",
    "\n",
    "    for vn in lst:\n",
    "        Xtraindata[vn] = Dictdf[vn]\n",
    "    X_train = Xtraindata.reset_index(drop =True).fillna(value = 0)     \n",
    "    scaler = StandardScaler()\n",
    "\n",
    "# X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    X_train_std = scaler.fit_transform(X_train)\n",
    "    X_pca_d_sa4_new = pcafit.transform(X_train_std)\n",
    "\n",
    "    PCnames = []\n",
    "    for i in range(1, d3 + 1, 1):\n",
    "        PCnames.append(f\"sa4PC{i}\")  \n",
    "    \n",
    "    pcadf = pd.DataFrame(X_pca_d_sa4_new , columns=PCnames)\n",
    "    pcadf['date'] = avg_1_y.reset_index()['date'][1:21].reset_index(drop= True)\n",
    "    pcadf= pcadf.set_index(\"date\")    \n",
    "    \n",
    "    df1 = pd.concat([pcadf,avg_1['l0']], axis=1, join = \"outer\")\n",
    "    df2 = avg_3.loc[avg_3['sa4'] == key].set_index('date')\n",
    "    df3 = pd.concat([df1,df2['l01']], axis=1,join = \"outer\")\n",
    "#     df4 = df3.interpolate(method='linear').interpolate(method=\"spline\", order=1, limit_direction=\"both\")\n",
    "    df4 = df3.interpolate(\"bfill\").interpolate(\"ffill\")\n",
    "    df4['l1'] = df4['l01'] - df4['l0']\n",
    "    pcadf_sa4_date_new = df4.drop(['l01', 'l0'], axis=1)\n",
    "\n",
    "    modelsa4 = VAR(pcadf_sa4_date_new)\n",
    "    result = modelsa4.fit(lag)\n",
    "    #print(\"Lag Order =\", lag)\n",
    "    #print(\"AIC : \", result.aic)\n",
    "    return(result.fpe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "9063c8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gamma2HQIC_VAR(key,pcafit,d3,lag):\n",
    "    Dictdf = DataFrameDict_Hsa4[key].interpolate(\"bfill\").interpolate(\"ffill\").loc[:, DataFrameDict_Hsa4[key].columns != \"date\"]\n",
    "    Xtraindata = pd.DataFrame([], columns = df_marks['Variable Names'].values)\n",
    "    lst = list(set(df_marks['Variable Names'].values) & set(Dictdf.columns.values))\n",
    "\n",
    "    for vn in lst:\n",
    "        Xtraindata[vn] = Dictdf[vn]\n",
    "    X_train = Xtraindata.reset_index(drop =True).fillna(value = 0)     \n",
    "    scaler = StandardScaler()\n",
    "\n",
    "# X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    X_train_std = scaler.fit_transform(X_train)\n",
    "    X_pca_d_sa4_new = pcafit.transform(X_train_std)\n",
    "\n",
    "    PCnames = []\n",
    "    for i in range(1, d3 + 1, 1):\n",
    "        PCnames.append(f\"sa4PC{i}\")  \n",
    "    \n",
    "    pcadf = pd.DataFrame(X_pca_d_sa4_new , columns=PCnames)\n",
    "    pcadf['date'] = avg_1_y.reset_index()['date'][1:21].reset_index(drop= True)\n",
    "    pcadf= pcadf.set_index(\"date\")    \n",
    "    \n",
    "    df1 = pd.concat([pcadf,avg_1['l0']], axis=1, join = \"outer\")\n",
    "    df2 = avg_3.loc[avg_3['sa4'] == key].set_index('date')\n",
    "    df3 = pd.concat([df1,df2['l01']], axis=1,join = \"outer\")\n",
    "#     df4 = df3.interpolate(method='linear').interpolate(method=\"spline\", order=1, limit_direction=\"both\")\n",
    "    df4 = df3.interpolate(\"bfill\").interpolate(\"ffill\")\n",
    "    df4['l1'] = df4['l01'] - df4['l0']\n",
    "    pcadf_sa4_date_new = df4.drop(['l01', 'l0'], axis=1)\n",
    "\n",
    "    modelsa4 = VAR(pcadf_sa4_date_new)\n",
    "    result = modelsa4.fit(lag)\n",
    "    #print(\"Lag Order =\", lag)\n",
    "    #print(\"AIC : \", result.aic)\n",
    "    return(result.hqic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "bb7a6d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gamma2pre_VAR(key,pcafit,d3,lag):\n",
    "    Dictdf = DataFrameDict_Hsa4[key].interpolate(\"bfill\").interpolate(\"ffill\").loc[:, DataFrameDict_Hsa4[key].columns != \"date\"]\n",
    "    Xtraindata = pd.DataFrame([], columns = df_marks['Variable Names'].values)\n",
    "    lst = list(set(df_marks['Variable Names'].values) & set(Dictdf.columns.values))\n",
    "\n",
    "    for vn in lst:\n",
    "        Xtraindata[vn] = Dictdf[vn]\n",
    "    X_train = Xtraindata.reset_index(drop =True).fillna(value = 0)     \n",
    "    scaler = StandardScaler()\n",
    "\n",
    "# X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    X_train_std = scaler.fit_transform(X_train)\n",
    "    X_pca_d_sa4_new = pcafit.transform(X_train_std)\n",
    "\n",
    "    PCnames = []\n",
    "    for i in range(1, d3 + 1, 1):\n",
    "        PCnames.append(f\"sa4PC{i}\")  \n",
    "    \n",
    "    pcadf = pd.DataFrame(X_pca_d_sa4_new , columns=PCnames)\n",
    "    pcadf['date'] = avg_1_y.reset_index()['date'][1:21].reset_index(drop= True)\n",
    "    pcadf= pcadf.set_index(\"date\")    \n",
    "    \n",
    "    df1 = pd.concat([pcadf,avg_1['l0']], axis=1, join = \"outer\")\n",
    "    df2 = avg_3.loc[avg_3['sa4'] == key].set_index('date')\n",
    "    df3 = pd.concat([df1,df2['l01']], axis=1,join = \"outer\")\n",
    "#     df4 = df3.interpolate(method='linear').interpolate(method=\"spline\", order=1, limit_direction=\"both\")\n",
    "    df4 = df3.interpolate(\"bfill\").interpolate(\"ffill\")\n",
    "    df4['l1'] = df4['l01'] - df4['l0']\n",
    "    pcadf_sa4_date_new = df4.drop(['l01', 'l0'], axis=1)\n",
    "    pcadf_sa4_date_new = pcadf_sa4_date_new.reset_index() \n",
    "    df5= pcadf_sa4_date_new.loc[(\"2020-01\" >pcadf_sa4_date_new[\"date\"])&(pcadf_sa4_date_new[\"date\"]> \"2000-12\")].reset_index(drop = True)\n",
    "    df = df5.iloc[:,1:]\n",
    "\n",
    "    modelsa4 = VAR(df)\n",
    "    model_fitted = modelsa4.fit(lag)\n",
    "    \n",
    "    lag_order = model_fitted.k_ar\n",
    "    forecast_input = df\n",
    "    start_point = lag_order \n",
    "\n",
    "    df_forecast = []\n",
    "    for i in range(1,df.shape[0]-lag_order+1, 1):\n",
    "        forecast_input = df.values[\n",
    "            -lag_order + start_point + i - 1 : start_point + i - 1,\n",
    "        ]\n",
    "        df_forecast.append(\n",
    "            model_fitted.forecast(y=forecast_input, steps=1)[\n",
    "                0,\n",
    "            ][-1]\n",
    "        )\n",
    "    avg_3_pred_sa4 = pd.DataFrame(df_forecast, columns=[\"l1_forecast\"])\n",
    "    #print(\"Lag Order =\", lag)\n",
    "    #print(\"AIC : \", result.aic)\n",
    "    return(avg_3_pred_sa4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "cf13f1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gamma2rf(key,pcafit,d3,lag):\n",
    "    Dictdf = DataFrameDict_Hsa4[key].interpolate(\"bfill\").interpolate(\"ffill\").loc[:, DataFrameDict_Hsa4[key].columns != \"date\"]\n",
    "    Xtraindata = pd.DataFrame([], columns = df_marks['Variable Names'].values)\n",
    "    lst = list(set(df_marks['Variable Names'].values) & set(Dictdf.columns.values))\n",
    "\n",
    "    for vn in lst:\n",
    "        Xtraindata[vn] = Dictdf[vn]\n",
    "    X_train = Xtraindata.reset_index(drop =True).fillna(value = 0)     \n",
    "    scaler = StandardScaler()\n",
    "\n",
    "# X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    X_train_std = scaler.fit_transform(X_train)\n",
    "    X_pca_d_sa4_new = pcafit.transform(X_train_std)\n",
    "\n",
    "    PCnames = []\n",
    "    for i in range(1, d3 + 1, 1):\n",
    "        PCnames.append(f\"sa4PC{i}\")  \n",
    "    \n",
    "    pcadf = pd.DataFrame(X_pca_d_sa4_new , columns=PCnames)\n",
    "    pcadf['date'] = avg_1_y.reset_index()['date'][1:21].reset_index(drop= True)\n",
    "    pcadf= pcadf.set_index(\"date\")    \n",
    "    #print(\"Lag Order =\", lag)\n",
    "    #print(\"AIC : \", result.aic)\n",
    "    return(pcadf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9510ebd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.050505050505051"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gammaList[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "480bf920",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leiflyu/miniforge3/lib/python3.9/site-packages/statsmodels/regression/linear_model.py:940: RuntimeWarning: divide by zero encountered in log\n",
      "  llf = -nobs2*np.log(2*np.pi) - nobs2*np.log(ssr / nobs) - nobs2\n",
      "/Users/leiflyu/miniforge3/lib/python3.9/site-packages/statsmodels/regression/linear_model.py:940: RuntimeWarning: divide by zero encountered in log\n",
      "  llf = -nobs2*np.log(2*np.pi) - nobs2*np.log(ssr / nobs) - nobs2\n",
      "/Users/leiflyu/miniforge3/lib/python3.9/site-packages/statsmodels/regression/linear_model.py:940: RuntimeWarning: divide by zero encountered in log\n",
      "  llf = -nobs2*np.log(2*np.pi) - nobs2*np.log(ssr / nobs) - nobs2\n",
      "/Users/leiflyu/miniforge3/lib/python3.9/site-packages/statsmodels/regression/linear_model.py:940: RuntimeWarning: divide by zero encountered in log\n",
      "  llf = -nobs2*np.log(2*np.pi) - nobs2*np.log(ssr / nobs) - nobs2\n",
      "/Users/leiflyu/miniforge3/lib/python3.9/site-packages/statsmodels/regression/linear_model.py:940: RuntimeWarning: divide by zero encountered in log\n",
      "  llf = -nobs2*np.log(2*np.pi) - nobs2*np.log(ssr / nobs) - nobs2\n",
      "/Users/leiflyu/miniforge3/lib/python3.9/site-packages/statsmodels/regression/linear_model.py:940: RuntimeWarning: divide by zero encountered in log\n",
      "  llf = -nobs2*np.log(2*np.pi) - nobs2*np.log(ssr / nobs) - nobs2\n",
      "/Users/leiflyu/miniforge3/lib/python3.9/site-packages/statsmodels/regression/linear_model.py:940: RuntimeWarning: divide by zero encountered in log\n",
      "  llf = -nobs2*np.log(2*np.pi) - nobs2*np.log(ssr / nobs) - nobs2\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as statm\n",
    "from statistics import mean\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "gamma_final = gammaList[2]\n",
    "d3_final, pcafit_final = PCA_val(gamma_final,df_marks,vrdata)\n",
    "lag_final = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "204e28b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_3_pred_values= []\n",
    "lst = [\"date\",\"sa4\", \"l0_fc\", \"l1_fc\", \"l01_fc\"]\n",
    "# Calling DataFrame constructor on list\n",
    "for key in DataFrameDict_Hsa4.keys():    \n",
    "    try:\n",
    "        df = pd.DataFrame([], columns=lst)\n",
    "        df1 = avg_1_pred.reset_index()\n",
    "        df[\"date\"] = df1[\"date\"].loc[(\"2020-01\" >df1[\"date\"])& (df1[\"date\"] > \"1999-12\")]\n",
    "        df[\"sa4\"] = key \n",
    "        df[\"l0_fc\"] = df1[\"l0_forecast\"].loc[(\"2020-01\" >df1[\"date\"])& (df1[\"date\"] > \"1999-12\")]\n",
    "        df[\"l1_fc\"] = gamma2pre_VAR(key, pcafit_final, d3_final, lag_final)[\"l1_forecast\"]\n",
    "        df[\"l01_fc\"]  = df[\"l0_fc\"] + df[\"l1_fc\"]\n",
    "        avg_3_pred_values.append(df)\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "avg_3_pred = pd.concat(avg_3_pred_values)\n",
    "avg_3_pred = avg_3_pred.reset_index(drop=True)\n",
    "avg_3_pred['date'] = pd.to_datetime(avg_3_pred['date'],errors = 'coerce')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e59e3a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_3_pred = avg_3_pred.drop(['l0_fc', 'l1_fc'], axis=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "ea6accd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leiflyu/miniforge3/lib/python3.9/site-packages/statsmodels/regression/linear_model.py:1754: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return 1 - self.ssr/self.uncentered_tss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4670\n",
      "Wide Bay\n",
      "4655\n",
      "Wide Bay\n",
      "4650\n",
      "Wide Bay\n",
      "4615\n",
      "Wide Bay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leiflyu/miniforge3/lib/python3.9/site-packages/statsmodels/regression/linear_model.py:1754: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "/Users/leiflyu/miniforge3/lib/python3.9/site-packages/statsmodels/regression/linear_model.py:1754: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "/Users/leiflyu/miniforge3/lib/python3.9/site-packages/statsmodels/regression/linear_model.py:1754: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "/Users/leiflyu/miniforge3/lib/python3.9/site-packages/statsmodels/regression/linear_model.py:1754: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return 1 - self.ssr/self.uncentered_tss\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.11998853082572587"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rsq = []\n",
    "MSE = []\n",
    "postcode_list_OLS = []\n",
    "sa4_list_OLS = []\n",
    "for key in DataFrameDict_postcode.keys():\n",
    "    try:\n",
    "        df = pd.DataFrame([])\n",
    "        sa4_name =  DataFrameDict_postcode[key][\"sa4_name16\"].unique()[0]\n",
    "        df_rf_sa4 = gamma2rf(sa4_name,pcafit_final,d3_final,lag_final)\n",
    "        df_rf_nat = PC_nat\n",
    "        df1 = df_rf_nat.join(df_rf_sa4)\n",
    "        df2 = df1.join(avg_4.loc[avg_4['postcode'] == key].set_index('date'))\n",
    "        df3 = df2.join(avg_3.loc[avg_3['sa4'] == sa4_name].set_index('date'))\n",
    "        df4 = df3.interpolate(method='linear').interpolate(method=\"spline\", order=1, limit_direction=\"both\")\n",
    "        df4['l2'] = df4['l012'] - df4['l01']\n",
    "        df5 = df4.drop(['postcode','sa4','l012', 'l01'], axis=1)    \n",
    "        df6 = df1.interpolate(\"bfill\").interpolate(\"ffill\").reset_index()\n",
    "        df6['date'] = df6['date'].astype(str)\n",
    "        month = [int(my_str.split(\"-\")[1]) for my_str in df6[\"date\"].values]\n",
    "        quater = [(m - 1) // 3 + 1 for m in month]\n",
    "        monthdummies = pd.get_dummies(month, prefix=\"month\").iloc[:,:-1]\n",
    "        quaterdummies = pd.get_dummies(quater, prefix=\"quater\").iloc[:,:-1]\n",
    "        dummies = pd.concat([monthdummies, quaterdummies], axis=1)\n",
    "        df7 =  pd.concat([df6,dummies],axis =1)\n",
    "        X = df7.iloc[:, 1:].values\n",
    "        y = df5.iloc[:, -1].values\n",
    "        #result = statm.OLS(y, X).fit()\n",
    "        result = statm.OLS(y, X).fit()\n",
    "        Rsq.append(result.rsquared)\n",
    "        MSE.append(result.mse_total)\n",
    "        sa4_list_OLS.append(sa4_name)\n",
    "        postcode_list_OLS.append(key)\n",
    "        \n",
    "    except:\n",
    "        print(key)\n",
    "        print(sa4_name)\n",
    "        pass\n",
    "        \n",
    "cleanedRsq = [x for x in Rsq if str(x) != \"nan\"]\n",
    "mean(cleanedRsq)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "3906a2a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.016594842273953272"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanedMSE = [x for x in MSE if str(x) != \"nan\"]\n",
    "mean(cleanedMSE)**(1/2)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "cdf5b7ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postcode</th>\n",
       "      <th>date</th>\n",
       "      <th>l012</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0810</td>\n",
       "      <td>1999-12-31</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0810</td>\n",
       "      <td>2000-01-31</td>\n",
       "      <td>0.020189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0810</td>\n",
       "      <td>2000-02-29</td>\n",
       "      <td>0.002960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0810</td>\n",
       "      <td>2000-03-31</td>\n",
       "      <td>0.004537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0810</td>\n",
       "      <td>2000-04-30</td>\n",
       "      <td>-0.034695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111819</th>\n",
       "      <td>7321</td>\n",
       "      <td>2019-08-31</td>\n",
       "      <td>-0.021176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111820</th>\n",
       "      <td>7321</td>\n",
       "      <td>2019-09-30</td>\n",
       "      <td>-0.005944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111821</th>\n",
       "      <td>7321</td>\n",
       "      <td>2019-10-31</td>\n",
       "      <td>0.052299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111822</th>\n",
       "      <td>7321</td>\n",
       "      <td>2019-11-30</td>\n",
       "      <td>0.025115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111823</th>\n",
       "      <td>7321</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>0.003374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111824 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       postcode       date      l012\n",
       "0          0810 1999-12-31       NaN\n",
       "1          0810 2000-01-31  0.020189\n",
       "2          0810 2000-02-29  0.002960\n",
       "3          0810 2000-03-31  0.004537\n",
       "4          0810 2000-04-30 -0.034695\n",
       "...         ...        ...       ...\n",
       "111819     7321 2019-08-31 -0.021176\n",
       "111820     7321 2019-09-30 -0.005944\n",
       "111821     7321 2019-10-31  0.052299\n",
       "111822     7321 2019-11-30  0.025115\n",
       "111823     7321 2019-12-31  0.003374\n",
       "\n",
       "[111824 rows x 3 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "d07d1a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pathlib import Path  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "83d06dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepath = Path('observations.csv')  \n",
    "observation = avg_4.pivot(index='date',columns='postcode',values = 'l012')[1:]\n",
    "# observation.to_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "8f824cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepath = Path('knownvariables.csv')  \n",
    "# PC_nat.to_csv(index = False)\n",
    "# PC_nat.to_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "6bf929c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_FAVAR = pd.read_csv(\"./RF_FAVAR.csv\").iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "a9614d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>VAR Order Selection (* highlights the minimums)</caption>\n",
       "<tr>\n",
       "   <td></td>      <th>AIC</th>         <th>BIC</th>         <th>FPE</th>        <th>HQIC</th>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>0</th>  <td>     21.50</td>  <td>     21.74</td>  <td> 2.166e+09</td>  <td>     21.59</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1</th>  <td>     12.00</td>  <td>     16.09*</td> <td> 1.638e+05</td>  <td>     13.65*</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2</th>  <td>     12.00</td>  <td>     19.94</td>  <td> 1.677e+05</td>  <td>     15.20</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3</th>  <td>     11.84</td>  <td>     23.64</td>  <td> 1.551e+05*</td> <td>     16.60</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4</th>  <td>     12.31</td>  <td>     27.95</td>  <td> 2.873e+05</td>  <td>     18.62</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5</th>  <td>     12.35</td>  <td>     31.84</td>  <td> 3.880e+05</td>  <td>     20.22</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6</th>  <td>     11.96</td>  <td>     35.31</td>  <td> 3.953e+05</td>  <td>     21.38</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7</th>  <td>     11.83</td>  <td>     39.02</td>  <td> 6.335e+05</td>  <td>     22.80</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8</th>  <td>     11.25</td>  <td>     42.30</td>  <td> 8.659e+05</td>  <td>     23.78</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9</th>  <td>     10.24</td>  <td>     45.14</td>  <td> 1.126e+06</td>  <td>     24.32</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10</th> <td>     8.102</td>  <td>     46.85</td>  <td> 8.454e+05</td>  <td>     23.73</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>11</th> <td>     5.110</td>  <td>     47.71</td>  <td> 6.737e+05</td>  <td>     22.30</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>12</th> <td>   -0.4986*</td> <td>     45.95</td>  <td> 2.008e+05</td>  <td>     18.24</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_FAVAR = VAR(RF_FAVAR)\n",
    "\n",
    "x = model_FAVAR.select_order(maxlags=12)\n",
    "x.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "7413cdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_FARVA= pd.read_csv(\"./fitted_FARVA.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "254b7108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X0810</th>\n",
       "      <th>X0820</th>\n",
       "      <th>X0870</th>\n",
       "      <th>X2010</th>\n",
       "      <th>X2018</th>\n",
       "      <th>X2026</th>\n",
       "      <th>X2030</th>\n",
       "      <th>X2031</th>\n",
       "      <th>X2035</th>\n",
       "      <th>X2037</th>\n",
       "      <th>...</th>\n",
       "      <th>X7116</th>\n",
       "      <th>X7140</th>\n",
       "      <th>X7248</th>\n",
       "      <th>X7249</th>\n",
       "      <th>X7250</th>\n",
       "      <th>X7300</th>\n",
       "      <th>X7304</th>\n",
       "      <th>X7310</th>\n",
       "      <th>X7320</th>\n",
       "      <th>X7321</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.021228</td>\n",
       "      <td>0.013556</td>\n",
       "      <td>0.036559</td>\n",
       "      <td>0.001026</td>\n",
       "      <td>0.003353</td>\n",
       "      <td>-0.000591</td>\n",
       "      <td>-0.005746</td>\n",
       "      <td>0.009134</td>\n",
       "      <td>0.010990</td>\n",
       "      <td>0.001758</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011092</td>\n",
       "      <td>0.005424</td>\n",
       "      <td>-0.022995</td>\n",
       "      <td>-0.025949</td>\n",
       "      <td>-0.016893</td>\n",
       "      <td>0.020883</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>-0.003217</td>\n",
       "      <td>-0.013930</td>\n",
       "      <td>-0.008985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.000383</td>\n",
       "      <td>0.031949</td>\n",
       "      <td>0.019518</td>\n",
       "      <td>-0.008655</td>\n",
       "      <td>-0.008000</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>0.004373</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.008900</td>\n",
       "      <td>-0.005546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015777</td>\n",
       "      <td>0.014105</td>\n",
       "      <td>0.017530</td>\n",
       "      <td>0.011244</td>\n",
       "      <td>0.009738</td>\n",
       "      <td>0.028912</td>\n",
       "      <td>-0.003544</td>\n",
       "      <td>0.019986</td>\n",
       "      <td>0.027695</td>\n",
       "      <td>0.028455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.001023</td>\n",
       "      <td>0.012515</td>\n",
       "      <td>-0.003953</td>\n",
       "      <td>-0.000493</td>\n",
       "      <td>0.006958</td>\n",
       "      <td>0.004353</td>\n",
       "      <td>0.004633</td>\n",
       "      <td>0.016838</td>\n",
       "      <td>0.017174</td>\n",
       "      <td>-0.003516</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016969</td>\n",
       "      <td>0.020197</td>\n",
       "      <td>0.013501</td>\n",
       "      <td>0.008381</td>\n",
       "      <td>0.005770</td>\n",
       "      <td>0.002729</td>\n",
       "      <td>-0.012807</td>\n",
       "      <td>0.025704</td>\n",
       "      <td>0.021281</td>\n",
       "      <td>0.044162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.004265</td>\n",
       "      <td>-0.007280</td>\n",
       "      <td>-0.003205</td>\n",
       "      <td>0.007771</td>\n",
       "      <td>0.007987</td>\n",
       "      <td>-0.011809</td>\n",
       "      <td>-0.010761</td>\n",
       "      <td>-0.007455</td>\n",
       "      <td>-0.000312</td>\n",
       "      <td>0.008115</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001359</td>\n",
       "      <td>0.014614</td>\n",
       "      <td>0.011480</td>\n",
       "      <td>0.008810</td>\n",
       "      <td>0.013162</td>\n",
       "      <td>0.010342</td>\n",
       "      <td>0.008229</td>\n",
       "      <td>0.002869</td>\n",
       "      <td>-0.004827</td>\n",
       "      <td>0.004643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005408</td>\n",
       "      <td>-0.001789</td>\n",
       "      <td>-0.007804</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.004051</td>\n",
       "      <td>-0.011559</td>\n",
       "      <td>-0.014706</td>\n",
       "      <td>-0.009949</td>\n",
       "      <td>-0.007980</td>\n",
       "      <td>0.002838</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030277</td>\n",
       "      <td>0.048328</td>\n",
       "      <td>0.008144</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.008505</td>\n",
       "      <td>0.009038</td>\n",
       "      <td>0.003255</td>\n",
       "      <td>0.034098</td>\n",
       "      <td>0.020385</td>\n",
       "      <td>0.040992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>-0.018479</td>\n",
       "      <td>-0.014374</td>\n",
       "      <td>-0.015421</td>\n",
       "      <td>0.034045</td>\n",
       "      <td>0.026843</td>\n",
       "      <td>0.036143</td>\n",
       "      <td>0.037095</td>\n",
       "      <td>0.017473</td>\n",
       "      <td>0.018393</td>\n",
       "      <td>0.036618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007557</td>\n",
       "      <td>0.001407</td>\n",
       "      <td>0.005277</td>\n",
       "      <td>0.011339</td>\n",
       "      <td>0.007484</td>\n",
       "      <td>-0.009765</td>\n",
       "      <td>-0.001700</td>\n",
       "      <td>-0.013143</td>\n",
       "      <td>0.001006</td>\n",
       "      <td>-0.020575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>-0.008620</td>\n",
       "      <td>-0.001311</td>\n",
       "      <td>0.006241</td>\n",
       "      <td>0.032927</td>\n",
       "      <td>0.033524</td>\n",
       "      <td>0.039911</td>\n",
       "      <td>0.036562</td>\n",
       "      <td>0.029807</td>\n",
       "      <td>0.030194</td>\n",
       "      <td>0.038942</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008340</td>\n",
       "      <td>0.006191</td>\n",
       "      <td>0.004586</td>\n",
       "      <td>0.008110</td>\n",
       "      <td>0.002146</td>\n",
       "      <td>0.004007</td>\n",
       "      <td>0.004195</td>\n",
       "      <td>-0.007485</td>\n",
       "      <td>0.003344</td>\n",
       "      <td>-0.002371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>0.004832</td>\n",
       "      <td>-0.001245</td>\n",
       "      <td>0.014846</td>\n",
       "      <td>0.035174</td>\n",
       "      <td>0.043413</td>\n",
       "      <td>0.036854</td>\n",
       "      <td>0.027959</td>\n",
       "      <td>0.045936</td>\n",
       "      <td>0.043614</td>\n",
       "      <td>0.039236</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003183</td>\n",
       "      <td>0.008448</td>\n",
       "      <td>-0.001946</td>\n",
       "      <td>-0.000652</td>\n",
       "      <td>-0.006419</td>\n",
       "      <td>0.001780</td>\n",
       "      <td>0.003278</td>\n",
       "      <td>0.001601</td>\n",
       "      <td>-0.003039</td>\n",
       "      <td>0.013329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>-0.013320</td>\n",
       "      <td>-0.004860</td>\n",
       "      <td>-0.012846</td>\n",
       "      <td>0.050336</td>\n",
       "      <td>0.047015</td>\n",
       "      <td>0.061554</td>\n",
       "      <td>0.063140</td>\n",
       "      <td>0.036978</td>\n",
       "      <td>0.041518</td>\n",
       "      <td>0.054481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022790</td>\n",
       "      <td>0.015203</td>\n",
       "      <td>0.011533</td>\n",
       "      <td>0.016223</td>\n",
       "      <td>0.015565</td>\n",
       "      <td>-0.002421</td>\n",
       "      <td>0.008075</td>\n",
       "      <td>-0.004778</td>\n",
       "      <td>0.010331</td>\n",
       "      <td>-0.001735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>0.000437</td>\n",
       "      <td>-0.007493</td>\n",
       "      <td>0.004161</td>\n",
       "      <td>0.037573</td>\n",
       "      <td>0.037733</td>\n",
       "      <td>0.033009</td>\n",
       "      <td>0.030001</td>\n",
       "      <td>0.027240</td>\n",
       "      <td>0.026810</td>\n",
       "      <td>0.037765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023938</td>\n",
       "      <td>0.020999</td>\n",
       "      <td>0.007221</td>\n",
       "      <td>0.009159</td>\n",
       "      <td>0.006759</td>\n",
       "      <td>0.003256</td>\n",
       "      <td>0.017401</td>\n",
       "      <td>0.003306</td>\n",
       "      <td>0.008926</td>\n",
       "      <td>0.004285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows  464 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        X0810     X0820     X0870     X2010     X2018     X2026     X2030  \\\n",
       "0    0.021228  0.013556  0.036559  0.001026  0.003353 -0.000591 -0.005746   \n",
       "1   -0.000383  0.031949  0.019518 -0.008655 -0.008000  0.001709  0.004373   \n",
       "2   -0.001023  0.012515 -0.003953 -0.000493  0.006958  0.004353  0.004633   \n",
       "3    0.004265 -0.007280 -0.003205  0.007771  0.007987 -0.011809 -0.010761   \n",
       "4    0.005408 -0.001789 -0.007804  0.000418  0.004051 -0.011559 -0.014706   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "235 -0.018479 -0.014374 -0.015421  0.034045  0.026843  0.036143  0.037095   \n",
       "236 -0.008620 -0.001311  0.006241  0.032927  0.033524  0.039911  0.036562   \n",
       "237  0.004832 -0.001245  0.014846  0.035174  0.043413  0.036854  0.027959   \n",
       "238 -0.013320 -0.004860 -0.012846  0.050336  0.047015  0.061554  0.063140   \n",
       "239  0.000437 -0.007493  0.004161  0.037573  0.037733  0.033009  0.030001   \n",
       "\n",
       "        X2031     X2035     X2037  ...     X7116     X7140     X7248  \\\n",
       "0    0.009134  0.010990  0.001758  ...  0.011092  0.005424 -0.022995   \n",
       "1    0.008000  0.008900 -0.005546  ...  0.015777  0.014105  0.017530   \n",
       "2    0.016838  0.017174 -0.003516  ...  0.016969  0.020197  0.013501   \n",
       "3   -0.007455 -0.000312  0.008115  ...  0.001359  0.014614  0.011480   \n",
       "4   -0.009949 -0.007980  0.002838  ...  0.030277  0.048328  0.008144   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "235  0.017473  0.018393  0.036618  ...  0.007557  0.001407  0.005277   \n",
       "236  0.029807  0.030194  0.038942  ...  0.008340  0.006191  0.004586   \n",
       "237  0.045936  0.043614  0.039236  ...  0.003183  0.008448 -0.001946   \n",
       "238  0.036978  0.041518  0.054481  ...  0.022790  0.015203  0.011533   \n",
       "239  0.027240  0.026810  0.037765  ...  0.023938  0.020999  0.007221   \n",
       "\n",
       "        X7249     X7250     X7300     X7304     X7310     X7320     X7321  \n",
       "0   -0.025949 -0.016893  0.020883  0.001235 -0.003217 -0.013930 -0.008985  \n",
       "1    0.011244  0.009738  0.028912 -0.003544  0.019986  0.027695  0.028455  \n",
       "2    0.008381  0.005770  0.002729 -0.012807  0.025704  0.021281  0.044162  \n",
       "3    0.008810  0.013162  0.010342  0.008229  0.002869 -0.004827  0.004643  \n",
       "4    0.000537  0.008505  0.009038  0.003255  0.034098  0.020385  0.040992  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "235  0.011339  0.007484 -0.009765 -0.001700 -0.013143  0.001006 -0.020575  \n",
       "236  0.008110  0.002146  0.004007  0.004195 -0.007485  0.003344 -0.002371  \n",
       "237 -0.000652 -0.006419  0.001780  0.003278  0.001601 -0.003039  0.013329  \n",
       "238  0.016223  0.015565 -0.002421  0.008075 -0.004778  0.010331 -0.001735  \n",
       "239  0.009159  0.006759  0.003256  0.017401  0.003306  0.008926  0.004285  \n",
       "\n",
       "[240 rows x 464 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_FARVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "ecb0502d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>postcode</th>\n",
       "      <th>0810</th>\n",
       "      <th>0820</th>\n",
       "      <th>0870</th>\n",
       "      <th>2010</th>\n",
       "      <th>2018</th>\n",
       "      <th>2026</th>\n",
       "      <th>2030</th>\n",
       "      <th>2031</th>\n",
       "      <th>2035</th>\n",
       "      <th>2037</th>\n",
       "      <th>...</th>\n",
       "      <th>7116</th>\n",
       "      <th>7140</th>\n",
       "      <th>7248</th>\n",
       "      <th>7249</th>\n",
       "      <th>7250</th>\n",
       "      <th>7300</th>\n",
       "      <th>7304</th>\n",
       "      <th>7310</th>\n",
       "      <th>7320</th>\n",
       "      <th>7321</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-31</th>\n",
       "      <td>0.020189</td>\n",
       "      <td>-0.020570</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>-0.002303</td>\n",
       "      <td>-0.007156</td>\n",
       "      <td>0.006487</td>\n",
       "      <td>0.002827</td>\n",
       "      <td>0.005375</td>\n",
       "      <td>0.005856</td>\n",
       "      <td>-0.020047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031232</td>\n",
       "      <td>0.025301</td>\n",
       "      <td>-0.043766</td>\n",
       "      <td>-0.050148</td>\n",
       "      <td>-0.019182</td>\n",
       "      <td>0.056390</td>\n",
       "      <td>-0.008168</td>\n",
       "      <td>0.012710</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.000273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-02-29</th>\n",
       "      <td>0.002960</td>\n",
       "      <td>0.059627</td>\n",
       "      <td>0.031578</td>\n",
       "      <td>0.027258</td>\n",
       "      <td>0.009419</td>\n",
       "      <td>-0.007930</td>\n",
       "      <td>-0.018756</td>\n",
       "      <td>0.014057</td>\n",
       "      <td>0.029034</td>\n",
       "      <td>-0.005590</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047395</td>\n",
       "      <td>0.008250</td>\n",
       "      <td>0.019142</td>\n",
       "      <td>-0.010766</td>\n",
       "      <td>-0.005046</td>\n",
       "      <td>0.058459</td>\n",
       "      <td>-0.058029</td>\n",
       "      <td>-0.041234</td>\n",
       "      <td>0.009367</td>\n",
       "      <td>0.020141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-03-31</th>\n",
       "      <td>0.004537</td>\n",
       "      <td>0.006877</td>\n",
       "      <td>0.014223</td>\n",
       "      <td>-0.001159</td>\n",
       "      <td>0.010475</td>\n",
       "      <td>0.027292</td>\n",
       "      <td>0.047378</td>\n",
       "      <td>0.019209</td>\n",
       "      <td>0.035829</td>\n",
       "      <td>-0.005227</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017839</td>\n",
       "      <td>0.039976</td>\n",
       "      <td>0.038391</td>\n",
       "      <td>0.017078</td>\n",
       "      <td>0.006406</td>\n",
       "      <td>-0.008055</td>\n",
       "      <td>0.012144</td>\n",
       "      <td>0.027340</td>\n",
       "      <td>0.013773</td>\n",
       "      <td>0.108010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-04-30</th>\n",
       "      <td>-0.034695</td>\n",
       "      <td>-0.022285</td>\n",
       "      <td>-0.053188</td>\n",
       "      <td>0.018882</td>\n",
       "      <td>0.013574</td>\n",
       "      <td>0.006972</td>\n",
       "      <td>0.024476</td>\n",
       "      <td>-0.003070</td>\n",
       "      <td>-0.011066</td>\n",
       "      <td>0.019113</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055877</td>\n",
       "      <td>0.011292</td>\n",
       "      <td>0.003829</td>\n",
       "      <td>0.009853</td>\n",
       "      <td>0.010914</td>\n",
       "      <td>0.031640</td>\n",
       "      <td>0.029443</td>\n",
       "      <td>-0.012335</td>\n",
       "      <td>0.009415</td>\n",
       "      <td>-0.023166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-05-31</th>\n",
       "      <td>0.014369</td>\n",
       "      <td>-0.018193</td>\n",
       "      <td>0.003652</td>\n",
       "      <td>0.003586</td>\n",
       "      <td>-0.009754</td>\n",
       "      <td>-0.025243</td>\n",
       "      <td>-0.007891</td>\n",
       "      <td>-0.007005</td>\n",
       "      <td>-0.019157</td>\n",
       "      <td>0.020838</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008497</td>\n",
       "      <td>0.030387</td>\n",
       "      <td>-0.024592</td>\n",
       "      <td>-0.036001</td>\n",
       "      <td>0.005832</td>\n",
       "      <td>-0.072755</td>\n",
       "      <td>0.019835</td>\n",
       "      <td>0.042236</td>\n",
       "      <td>-0.041787</td>\n",
       "      <td>0.006769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-31</th>\n",
       "      <td>-0.062650</td>\n",
       "      <td>-0.030905</td>\n",
       "      <td>0.016077</td>\n",
       "      <td>0.042753</td>\n",
       "      <td>0.023378</td>\n",
       "      <td>0.083852</td>\n",
       "      <td>0.065679</td>\n",
       "      <td>-0.027588</td>\n",
       "      <td>-0.023130</td>\n",
       "      <td>0.045988</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015750</td>\n",
       "      <td>0.036376</td>\n",
       "      <td>0.018488</td>\n",
       "      <td>0.016907</td>\n",
       "      <td>0.007547</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.023396</td>\n",
       "      <td>-0.013050</td>\n",
       "      <td>-0.015779</td>\n",
       "      <td>-0.021176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-30</th>\n",
       "      <td>-0.006093</td>\n",
       "      <td>0.020964</td>\n",
       "      <td>-0.003420</td>\n",
       "      <td>0.012014</td>\n",
       "      <td>0.018949</td>\n",
       "      <td>0.017984</td>\n",
       "      <td>0.012397</td>\n",
       "      <td>0.059275</td>\n",
       "      <td>0.042494</td>\n",
       "      <td>0.018811</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010972</td>\n",
       "      <td>-0.030421</td>\n",
       "      <td>0.014697</td>\n",
       "      <td>0.008799</td>\n",
       "      <td>0.006956</td>\n",
       "      <td>0.013339</td>\n",
       "      <td>0.010003</td>\n",
       "      <td>-0.007663</td>\n",
       "      <td>0.013438</td>\n",
       "      <td>-0.005944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-31</th>\n",
       "      <td>-0.000837</td>\n",
       "      <td>0.003963</td>\n",
       "      <td>-0.016764</td>\n",
       "      <td>0.041428</td>\n",
       "      <td>0.043548</td>\n",
       "      <td>-0.017992</td>\n",
       "      <td>-0.030913</td>\n",
       "      <td>0.029699</td>\n",
       "      <td>0.030041</td>\n",
       "      <td>0.031836</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.011599</td>\n",
       "      <td>0.012541</td>\n",
       "      <td>0.005214</td>\n",
       "      <td>-0.031703</td>\n",
       "      <td>0.014111</td>\n",
       "      <td>-0.004089</td>\n",
       "      <td>-0.001221</td>\n",
       "      <td>0.052299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-30</th>\n",
       "      <td>-0.035151</td>\n",
       "      <td>-0.024589</td>\n",
       "      <td>-0.031414</td>\n",
       "      <td>0.070327</td>\n",
       "      <td>0.045208</td>\n",
       "      <td>0.040728</td>\n",
       "      <td>0.038592</td>\n",
       "      <td>0.055457</td>\n",
       "      <td>0.062625</td>\n",
       "      <td>0.078695</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015460</td>\n",
       "      <td>0.032686</td>\n",
       "      <td>0.017827</td>\n",
       "      <td>0.022187</td>\n",
       "      <td>0.013714</td>\n",
       "      <td>-0.010510</td>\n",
       "      <td>0.045059</td>\n",
       "      <td>0.002495</td>\n",
       "      <td>0.017698</td>\n",
       "      <td>0.025115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>-0.002375</td>\n",
       "      <td>0.031548</td>\n",
       "      <td>0.035311</td>\n",
       "      <td>0.066128</td>\n",
       "      <td>0.058928</td>\n",
       "      <td>0.026579</td>\n",
       "      <td>0.008500</td>\n",
       "      <td>0.036181</td>\n",
       "      <td>0.051520</td>\n",
       "      <td>0.060520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071682</td>\n",
       "      <td>0.022899</td>\n",
       "      <td>0.010931</td>\n",
       "      <td>0.014399</td>\n",
       "      <td>0.003317</td>\n",
       "      <td>0.023621</td>\n",
       "      <td>0.043439</td>\n",
       "      <td>0.015123</td>\n",
       "      <td>0.003168</td>\n",
       "      <td>0.003374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows  464 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "postcode        0810      0820      0870      2010      2018      2026  \\\n",
       "date                                                                     \n",
       "2000-01-31  0.020189 -0.020570  0.005168 -0.002303 -0.007156  0.006487   \n",
       "2000-02-29  0.002960  0.059627  0.031578  0.027258  0.009419 -0.007930   \n",
       "2000-03-31  0.004537  0.006877  0.014223 -0.001159  0.010475  0.027292   \n",
       "2000-04-30 -0.034695 -0.022285 -0.053188  0.018882  0.013574  0.006972   \n",
       "2000-05-31  0.014369 -0.018193  0.003652  0.003586 -0.009754 -0.025243   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2019-08-31 -0.062650 -0.030905  0.016077  0.042753  0.023378  0.083852   \n",
       "2019-09-30 -0.006093  0.020964 -0.003420  0.012014  0.018949  0.017984   \n",
       "2019-10-31 -0.000837  0.003963 -0.016764  0.041428  0.043548 -0.017992   \n",
       "2019-11-30 -0.035151 -0.024589 -0.031414  0.070327  0.045208  0.040728   \n",
       "2019-12-31 -0.002375  0.031548  0.035311  0.066128  0.058928  0.026579   \n",
       "\n",
       "postcode        2030      2031      2035      2037  ...      7116      7140  \\\n",
       "date                                                ...                       \n",
       "2000-01-31  0.002827  0.005375  0.005856 -0.020047  ...  0.031232  0.025301   \n",
       "2000-02-29 -0.018756  0.014057  0.029034 -0.005590  ...  0.047395  0.008250   \n",
       "2000-03-31  0.047378  0.019209  0.035829 -0.005227  ...  0.017839  0.039976   \n",
       "2000-04-30  0.024476 -0.003070 -0.011066  0.019113  ...  0.055877  0.011292   \n",
       "2000-05-31 -0.007891 -0.007005 -0.019157  0.020838  ...  0.008497  0.030387   \n",
       "...              ...       ...       ...       ...  ...       ...       ...   \n",
       "2019-08-31  0.065679 -0.027588 -0.023130  0.045988  ... -0.015750  0.036376   \n",
       "2019-09-30  0.012397  0.059275  0.042494  0.018811  ...  0.010972 -0.030421   \n",
       "2019-10-31 -0.030913  0.029699  0.030041  0.031836  ...  0.001681  0.021872   \n",
       "2019-11-30  0.038592  0.055457  0.062625  0.078695  ...  0.015460  0.032686   \n",
       "2019-12-31  0.008500  0.036181  0.051520  0.060520  ...  0.071682  0.022899   \n",
       "\n",
       "postcode        7248      7249      7250      7300      7304      7310  \\\n",
       "date                                                                     \n",
       "2000-01-31 -0.043766 -0.050148 -0.019182  0.056390 -0.008168  0.012710   \n",
       "2000-02-29  0.019142 -0.010766 -0.005046  0.058459 -0.058029 -0.041234   \n",
       "2000-03-31  0.038391  0.017078  0.006406 -0.008055  0.012144  0.027340   \n",
       "2000-04-30  0.003829  0.009853  0.010914  0.031640  0.029443 -0.012335   \n",
       "2000-05-31 -0.024592 -0.036001  0.005832 -0.072755  0.019835  0.042236   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2019-08-31  0.018488  0.016907  0.007547  0.001235  0.023396 -0.013050   \n",
       "2019-09-30  0.014697  0.008799  0.006956  0.013339  0.010003 -0.007663   \n",
       "2019-10-31  0.011599  0.012541  0.005214 -0.031703  0.014111 -0.004089   \n",
       "2019-11-30  0.017827  0.022187  0.013714 -0.010510  0.045059  0.002495   \n",
       "2019-12-31  0.010931  0.014399  0.003317  0.023621  0.043439  0.015123   \n",
       "\n",
       "postcode        7320      7321  \n",
       "date                            \n",
       "2000-01-31  0.043669  0.000273  \n",
       "2000-02-29  0.009367  0.020141  \n",
       "2000-03-31  0.013773  0.108010  \n",
       "2000-04-30  0.009415 -0.023166  \n",
       "2000-05-31 -0.041787  0.006769  \n",
       "...              ...       ...  \n",
       "2019-08-31 -0.015779 -0.021176  \n",
       "2019-09-30  0.013438 -0.005944  \n",
       "2019-10-31 -0.001221  0.052299  \n",
       "2019-11-30  0.017698  0.025115  \n",
       "2019-12-31  0.003168  0.003374  \n",
       "\n",
       "[240 rows x 464 columns]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
